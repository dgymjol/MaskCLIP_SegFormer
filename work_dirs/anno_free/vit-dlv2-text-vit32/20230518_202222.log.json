{"env_info": "sys.platform: linux\nPython: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]\nCUDA available: True\nGPU 0: NVIDIA GeForce RTX 3090\nCUDA_HOME: /usr/local/cuda\nNVCC: Build cuda_11.8.r11.8/compiler.31833905_0\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\nPyTorch: 1.9.0+cu111\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.10.0+cu111\nOpenCV: 4.7.0\nMMCV: 1.4.0\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.1\nMMSegmentation: 0.20.2+03c38b7", "seed": 12289690, "exp_name": "maskclip_plus_vit16_deeplabv2_r101-d8_class_weight_480x480_4k_pascal_context_59.py", "mmseg_version": "0.20.2+03c38b7", "config": "norm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    type='EncoderDecoder',\n    pretrained='open-mmlab://resnet101_v1c',\n    backbone=dict(\n        type='ResNetV1c',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        dilations=(1, 1, 2, 4),\n        strides=(1, 2, 1, 1),\n        norm_cfg=dict(type='SyncBN', requires_grad=True),\n        norm_eval=False,\n        style='pytorch',\n        contract_dilation=True,\n        pretrained='open-mmlab://resnet101_v1c'),\n    decode_head=dict(\n        type='MaskClipPlusTextHead',\n        vit=True,\n        in_channels=2048,\n        channels=512,\n        num_classes=59,\n        dropout_ratio=0,\n        norm_cfg=dict(type='SyncBN', requires_grad=True),\n        loss_decode=dict(\n            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n        decode_module_cfg=dict(\n            type='ASPPHeadV2',\n            dilations=(6, 12, 18, 24),\n            in_channels=2048,\n            channels=512,\n            num_classes=59,\n            dropout_ratio=0,\n            norm_cfg=dict(type='SyncBN', requires_grad=True),\n            loss_decode=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            init_cfg=None),\n        text_categories=59,\n        text_channels=512,\n        clip_channels=768,\n        text_embeddings_path='pretrain/context_ViT16_clip_text.pth',\n        text_features_path='pretrain/context_ViT32_clip_text_features.pth',\n        tau=1,\n        cls_bg=False,\n        norm_feat=False,\n        clip_unlabeled_cats=[\n            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n            19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n            36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n            53, 54, 55, 56, 57, 58\n        ],\n        clip_cfg=dict(\n            type='VisionTransformer',\n            img_size=(224, 224),\n            patch_size=16,\n            patch_bias=False,\n            in_channels=3,\n            embed_dims=768,\n            num_layers=12,\n            num_heads=12,\n            mlp_ratio=4,\n            out_indices=-1,\n            qkv_bias=True,\n            drop_rate=0.0,\n            attn_drop_rate=0.0,\n            drop_path_rate=0.0,\n            with_cls_token=True,\n            output_cls_token=False,\n            norm_cfg=dict(type='LN', eps=1e-06),\n            act_cfg=dict(type='GELU'),\n            patch_norm=False,\n            pre_norm=True,\n            final_norm=True,\n            return_qkv=True,\n            interpolate_mode='bicubic',\n            num_fcs=2,\n            norm_eval=False),\n        clip_weights_path='pretrain/ViT16_clip_weights.pth',\n        reset_counter=True,\n        start_clip_guided=(1, -1),\n        start_self_train=(-1, -1)),\n    feed_img_to_decode_head=True,\n    train_cfg=dict(),\n    test_cfg=dict(mode='whole'))\ndataset_type = 'PascalContextDataset59'\ndata_root = 'data/VOCdevkit/VOC2010/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nimg_scale = (520, 520)\ncrop_size = (480, 480)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='LoadAnnotations',\n        reduce_zero_label=True,\n        suppress_labels=[\n            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n            19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n            36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n            53, 54, 55, 56, 57, 58\n        ]),\n    dict(type='Resize', img_scale=(520, 520), ratio_range=(0.5, 2.0)),\n    dict(type='RandomCrop', crop_size=(480, 480), cat_max_ratio=0.75),\n    dict(type='RandomFlip', prob=0.5),\n    dict(type='PhotoMetricDistortion'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size=(480, 480), pad_val=0, seg_pad_val=255),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(520, 520),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    train=dict(\n        type='PascalContextDataset59',\n        data_root='data/VOCdevkit/VOC2010/',\n        img_dir='JPEGImages',\n        ann_dir='SegmentationClassContext',\n        split='ImageSets/SegmentationContext/train.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='LoadAnnotations',\n                reduce_zero_label=True,\n                suppress_labels=[\n                    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n                    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n                    47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58\n                ]),\n            dict(type='Resize', img_scale=(520, 520), ratio_range=(0.5, 2.0)),\n            dict(type='RandomCrop', crop_size=(480, 480), cat_max_ratio=0.75),\n            dict(type='RandomFlip', prob=0.5),\n            dict(type='PhotoMetricDistortion'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size=(480, 480), pad_val=0, seg_pad_val=255),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n        ]),\n    val=dict(\n        type='PascalContextDataset59',\n        data_root='data/VOCdevkit/VOC2010/',\n        img_dir='JPEGImages',\n        ann_dir='SegmentationClassContext',\n        split='ImageSets/SegmentationContext/val.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(520, 520),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='PascalContextDataset59',\n        data_root='data/VOCdevkit/VOC2010/',\n        img_dir='JPEGImages',\n        ann_dir='SegmentationClassContext',\n        split='ImageSets/SegmentationContext/val.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(520, 520),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nlog_config = dict(\n    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\noptimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.00025)\noptimizer_config = dict()\nlr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\nrunner = dict(type='IterBasedRunner', max_iters=4000)\ncheckpoint_config = dict(by_epoch=False, interval=2000)\nevaluation = dict(interval=2000, metric='mIoU', pre_eval=True)\nsuppress_labels = [\n    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n    40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58\n]\nfind_unused_parameters = True\nwork_dir = 'work_dirs/anno_free/vit-dlv2-text'\ngpu_ids = range(0, 1)\nauto_resume = False\nseed = 12289690\n", "CLASSES": ["aeroplane", "bag", "bed", "bedclothes", "bench", "bicycle", "bird", "boat", "book", "bottle", "building", "bus", "cabinet", "car", "cat", "ceiling", "chair", "cloth", "computer", "cow", "cup", "curtain", "dog", "door", "fence", "floor", "flower", "food", "grass", "ground", "horse", "keyboard", "light", "motorbike", "mountain", "mouse", "person", "plate", "platform", "pottedplant", "road", "rock", "sheep", "shelves", "sidewalk", "sign", "sky", "snow", "sofa", "table", "track", "train", "tree", "truck", "tvmonitor", "wall", "water", "window", "wood"], "PALETTE": [[180, 120, 120], [6, 230, 230], [80, 50, 50], [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255], [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7], [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82], [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3], [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255], [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220], [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224], [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255], [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7], [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153], [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255], [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0], [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255], [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255]]}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00495, "memory": 17590, "data_time": 0.02193, "decode.loss_ce": 2.87922, "decode.acc_seg": 3.55073, "loss": 2.87922, "time": 0.9815}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.00489, "memory": 17590, "data_time": 0.01188, "decode.loss_ce": 2.56482, "decode.acc_seg": 10.92715, "loss": 2.56482, "time": 0.90006}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.00484, "memory": 17590, "data_time": 0.01239, "decode.loss_ce": 2.40027, "decode.acc_seg": 17.12156, "loss": 2.40027, "time": 0.89996}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00478, "memory": 17590, "data_time": 0.01225, "decode.loss_ce": 2.09366, "decode.acc_seg": 19.82398, "loss": 2.09366, "time": 0.902}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.00472, "memory": 17590, "data_time": 0.01236, "decode.loss_ce": 2.03308, "decode.acc_seg": 24.61468, "loss": 2.03308, "time": 0.90001}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.00467, "memory": 17590, "data_time": 0.01246, "decode.loss_ce": 1.93449, "decode.acc_seg": 23.62891, "loss": 1.93449, "time": 0.89997}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.00461, "memory": 17590, "data_time": 0.01268, "decode.loss_ce": 1.95602, "decode.acc_seg": 26.33792, "loss": 1.95602, "time": 0.90201}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.00456, "memory": 17590, "data_time": 0.01248, "decode.loss_ce": 1.84167, "decode.acc_seg": 27.7057, "loss": 1.84167, "time": 0.902}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.0045, "memory": 17590, "data_time": 0.01266, "decode.loss_ce": 1.78671, "decode.acc_seg": 26.39672, "loss": 1.78671, "time": 0.902}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.00445, "memory": 17590, "data_time": 0.01283, "decode.loss_ce": 1.82493, "decode.acc_seg": 26.7055, "loss": 1.82493, "time": 0.89999}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.00439, "memory": 17590, "data_time": 0.01303, "decode.loss_ce": 1.81445, "decode.acc_seg": 27.9714, "loss": 1.81445, "time": 0.9}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.00433, "memory": 17590, "data_time": 0.01294, "decode.loss_ce": 1.82324, "decode.acc_seg": 27.42271, "loss": 1.82324, "time": 0.89998}
{"mode": "train", "epoch": 2, "iter": 650, "lr": 0.00428, "memory": 17590, "data_time": 0.0594, "decode.loss_ce": 1.77156, "decode.acc_seg": 28.72531, "loss": 1.77156, "time": 0.94801}
{"mode": "train", "epoch": 2, "iter": 700, "lr": 0.00422, "memory": 17590, "data_time": 0.01287, "decode.loss_ce": 1.6691, "decode.acc_seg": 27.85616, "loss": 1.6691, "time": 0.89998}
{"mode": "train", "epoch": 2, "iter": 750, "lr": 0.00417, "memory": 17590, "data_time": 0.01302, "decode.loss_ce": 1.74073, "decode.acc_seg": 27.52192, "loss": 1.74073, "time": 0.90003}
{"mode": "train", "epoch": 2, "iter": 800, "lr": 0.00411, "memory": 17590, "data_time": 0.013, "decode.loss_ce": 1.70776, "decode.acc_seg": 29.62022, "loss": 1.70776, "time": 0.89999}
{"mode": "train", "epoch": 2, "iter": 850, "lr": 0.00405, "memory": 17590, "data_time": 0.01335, "decode.loss_ce": 1.79769, "decode.acc_seg": 29.75931, "loss": 1.79769, "time": 0.89996}
{"mode": "train", "epoch": 2, "iter": 900, "lr": 0.004, "memory": 17590, "data_time": 0.013, "decode.loss_ce": 1.66154, "decode.acc_seg": 29.34815, "loss": 1.66154, "time": 0.89999}
{"mode": "train", "epoch": 2, "iter": 950, "lr": 0.00394, "memory": 17590, "data_time": 0.01319, "decode.loss_ce": 1.72521, "decode.acc_seg": 29.90167, "loss": 1.72521, "time": 0.90001}
{"mode": "train", "epoch": 2, "iter": 1000, "lr": 0.00388, "memory": 17590, "data_time": 0.01318, "decode.loss_ce": 1.70895, "decode.acc_seg": 30.90953, "loss": 1.70895, "time": 0.9}
{"mode": "train", "epoch": 2, "iter": 1050, "lr": 0.00383, "memory": 17590, "data_time": 0.0132, "decode.loss_ce": 1.66773, "decode.acc_seg": 31.35863, "loss": 1.66773, "time": 0.89999}
{"mode": "train", "epoch": 2, "iter": 1100, "lr": 0.00377, "memory": 17590, "data_time": 0.01316, "decode.loss_ce": 1.53604, "decode.acc_seg": 31.07755, "loss": 1.53604, "time": 0.90196}
{"mode": "train", "epoch": 2, "iter": 1150, "lr": 0.00371, "memory": 17590, "data_time": 0.01333, "decode.loss_ce": 1.65658, "decode.acc_seg": 30.10496, "loss": 1.65658, "time": 0.90004}
{"mode": "train", "epoch": 2, "iter": 1200, "lr": 0.00366, "memory": 17590, "data_time": 0.0135, "decode.loss_ce": 1.69355, "decode.acc_seg": 29.32027, "loss": 1.69355, "time": 0.9}
{"mode": "train", "epoch": 3, "iter": 1250, "lr": 0.0036, "memory": 17590, "data_time": 0.05916, "decode.loss_ce": 1.6248, "decode.acc_seg": 30.36491, "loss": 1.6248, "time": 0.94596}
{"mode": "train", "epoch": 3, "iter": 1300, "lr": 0.00354, "memory": 17590, "data_time": 0.01303, "decode.loss_ce": 1.65354, "decode.acc_seg": 30.78649, "loss": 1.65354, "time": 0.90003}
{"mode": "train", "epoch": 3, "iter": 1350, "lr": 0.00348, "memory": 17590, "data_time": 0.01301, "decode.loss_ce": 1.63718, "decode.acc_seg": 31.89893, "loss": 1.63718, "time": 0.89999}
{"mode": "train", "epoch": 3, "iter": 1400, "lr": 0.00343, "memory": 17590, "data_time": 0.01308, "decode.loss_ce": 1.65987, "decode.acc_seg": 31.59171, "loss": 1.65987, "time": 0.90002}
{"mode": "train", "epoch": 3, "iter": 1450, "lr": 0.00337, "memory": 17590, "data_time": 0.01326, "decode.loss_ce": 1.61044, "decode.acc_seg": 32.369, "loss": 1.61044, "time": 0.90197}
{"mode": "train", "epoch": 3, "iter": 1500, "lr": 0.00331, "memory": 17590, "data_time": 0.01314, "decode.loss_ce": 1.57635, "decode.acc_seg": 31.92308, "loss": 1.57635, "time": 0.89998}
{"mode": "train", "epoch": 3, "iter": 1550, "lr": 0.00325, "memory": 17590, "data_time": 0.01321, "decode.loss_ce": 1.62864, "decode.acc_seg": 31.59614, "loss": 1.62864, "time": 0.9}
{"mode": "train", "epoch": 3, "iter": 1600, "lr": 0.0032, "memory": 17590, "data_time": 0.01327, "decode.loss_ce": 1.60508, "decode.acc_seg": 32.40697, "loss": 1.60508, "time": 0.90001}
{"mode": "train", "epoch": 3, "iter": 1650, "lr": 0.00314, "memory": 17590, "data_time": 0.01333, "decode.loss_ce": 1.56555, "decode.acc_seg": 31.48586, "loss": 1.56555, "time": 0.89998}
{"mode": "train", "epoch": 3, "iter": 1700, "lr": 0.00308, "memory": 17590, "data_time": 0.01325, "decode.loss_ce": 1.59136, "decode.acc_seg": 31.03713, "loss": 1.59136, "time": 0.90001}
{"mode": "train", "epoch": 3, "iter": 1750, "lr": 0.00302, "memory": 17590, "data_time": 0.01329, "decode.loss_ce": 1.56623, "decode.acc_seg": 32.46685, "loss": 1.56623, "time": 0.89998}
{"mode": "train", "epoch": 3, "iter": 1800, "lr": 0.00296, "memory": 17590, "data_time": 0.01344, "decode.loss_ce": 1.60861, "decode.acc_seg": 32.39014, "loss": 1.60861, "time": 0.90003}
{"mode": "train", "epoch": 3, "iter": 1850, "lr": 0.0029, "memory": 17590, "data_time": 0.01344, "decode.loss_ce": 1.58869, "decode.acc_seg": 32.74531, "loss": 1.58869, "time": 0.90001}
{"mode": "train", "epoch": 4, "iter": 1900, "lr": 0.00284, "memory": 17590, "data_time": 0.05947, "decode.loss_ce": 1.60472, "decode.acc_seg": 32.45587, "loss": 1.60472, "time": 0.94596}
{"mode": "train", "epoch": 4, "iter": 1950, "lr": 0.00279, "memory": 17590, "data_time": 0.01311, "decode.loss_ce": 1.60841, "decode.acc_seg": 33.07663, "loss": 1.60841, "time": 0.89999}
{"mode": "train", "epoch": 4, "iter": 2000, "lr": 0.00273, "memory": 17590, "data_time": 0.01304, "decode.loss_ce": 1.52961, "decode.acc_seg": 32.96144, "loss": 1.52961, "time": 0.9493}
{"mode": "val", "epoch": 4, "iter": 5104, "lr": 0.00273, "aAcc": 0.5698, "mIoU": 0.31, "mAcc": 0.4885, "mPrec": 0.4808, "IoU.aeroplane": 0.3895, "IoU.bag": 0.0, "IoU.bed": 0.0845, "IoU.bedclothes": 0.0596, "IoU.bench": 0.0, "IoU.bicycle": 0.5382, "IoU.bird": 0.6458, "IoU.boat": 0.3697, "IoU.book": 0.0, "IoU.bottle": 0.6239, "IoU.building": 0.1536, "IoU.bus": 0.7598, "IoU.cabinet": 0.1003, "IoU.car": 0.6633, "IoU.cat": 0.7639, "IoU.ceiling": 0.3155, "IoU.chair": 0.265, "IoU.cloth": 0.0579, "IoU.computer": 0.0593, "IoU.cow": 0.6875, "IoU.cup": 0.009, "IoU.curtain": 0.2896, "IoU.dog": 0.7523, "IoU.door": 0.0857, "IoU.fence": 0.1575, "IoU.floor": 0.4466, "IoU.flower": 0.1541, "IoU.food": 0.0661, "IoU.grass": 0.6282, "IoU.ground": 0.2424, "IoU.horse": 0.5624, "IoU.keyboard": 0.4474, "IoU.light": 0.1596, "IoU.motorbike": 0.6144, "IoU.mountain": 0.3329, "IoU.mouse": 0.0, "IoU.person": 0.5047, "IoU.plate": 0.0015, "IoU.platform": 0.0, "IoU.pottedplant": 0.3648, "IoU.road": 0.4044, "IoU.rock": 0.2827, "IoU.sheep": 0.7187, "IoU.shelves": 0.0016, "IoU.sidewalk": 0.1144, "IoU.sign": 0.2397, "IoU.sky": 0.5638, "IoU.snow": 0.3929, "IoU.sofa": 0.365, "IoU.table": 0.1588, "IoU.track": 0.0, "IoU.train": 0.4688, "IoU.tree": 0.4734, "IoU.truck": 0.0891, "IoU.tvmonitor": 0.4754, "IoU.wall": 0.3181, "IoU.water": 0.6728, "IoU.window": 0.1263, "IoU.wood": 0.0665, "Acc.aeroplane": 0.9651, "Acc.bag": 0.0, "Acc.bed": 0.3397, "Acc.bedclothes": 0.0639, "Acc.bench": 0.0, "Acc.bicycle": 0.9131, "Acc.bird": 0.9392, "Acc.boat": 0.8533, "Acc.book": 0.0, "Acc.bottle": 0.8104, "Acc.building": 0.1579, "Acc.bus": 0.916, "Acc.cabinet": 0.2572, "Acc.car": 0.9107, "Acc.cat": 0.9712, "Acc.ceiling": 0.7179, "Acc.chair": 0.3279, "Acc.cloth": 0.2808, "Acc.computer": 0.2204, "Acc.cow": 0.8553, "Acc.cup": 0.0105, "Acc.curtain": 0.3639, "Acc.dog": 0.8775, "Acc.door": 0.5503, "Acc.fence": 0.1821, "Acc.floor": 0.65, "Acc.flower": 0.3405, "Acc.food": 0.8656, "Acc.grass": 0.7512, "Acc.ground": 0.4373, "Acc.horse": 0.9254, "Acc.keyboard": 0.4751, "Acc.light": 0.4771, "Acc.motorbike": 0.8244, "Acc.mountain": 0.4635, "Acc.mouse": 0.0, "Acc.person": 0.5669, "Acc.plate": 0.0016, "Acc.platform": 0.0, "Acc.pottedplant": 0.7718, "Acc.road": 0.5748, "Acc.rock": 0.6415, "Acc.sheep": 0.8771, "Acc.shelves": 0.0016, "Acc.sidewalk": 0.6008, "Acc.sign": 0.3602, "Acc.sky": 0.5733, "Acc.snow": 0.447, "Acc.sofa": 0.4458, "Acc.table": 0.4383, "Acc.track": 0.0, "Acc.train": 0.8591, "Acc.tree": 0.5329, "Acc.truck": 0.1901, "Acc.tvmonitor": 0.5912, "Acc.wall": 0.3961, "Acc.water": 0.7478, "Acc.window": 0.1497, "Acc.wood": 0.3589, "Prec.aeroplane": 0.3951, "Prec.bag": 0.3488, "Prec.bed": 0.1011, "Prec.bedclothes": 0.4666, "Prec.bench": 0.0, "Prec.bicycle": 0.5673, "Prec.bird": 0.674, "Prec.boat": 0.3948, "Prec.book": 1.0, "Prec.bottle": 0.7306, "Prec.building": 0.8505, "Prec.bus": 0.8167, "Prec.cabinet": 0.1412, "Prec.car": 0.7094, "Prec.cat": 0.7815, "Prec.ceiling": 0.3601, "Prec.chair": 0.5799, "Prec.cloth": 0.0679, "Prec.computer": 0.075, "Prec.cow": 0.778, "Prec.cup": 0.0629, "Prec.curtain": 0.5866, "Prec.dog": 0.8406, "Prec.door": 0.0921, "Prec.fence": 0.5379, "Prec.floor": 0.5879, "Prec.flower": 0.2197, "Prec.food": 0.0668, "Prec.grass": 0.7932, "Prec.ground": 0.3522, "Prec.horse": 0.5891, "Prec.keyboard": 0.8846, "Prec.light": 0.1934, "Prec.motorbike": 0.707, "Prec.mountain": 0.5416, "Prec.mouse": NaN, "Prec.person": 0.8213, "Prec.plate": 0.0271, "Prec.platform": 0.0, "Prec.pottedplant": 0.4089, "Prec.road": 0.577, "Prec.rock": 0.3357, "Prec.sheep": 0.7991, "Prec.shelves": 0.2171, "Prec.sidewalk": 0.1238, "Prec.sign": 0.4175, "Prec.sky": 0.9715, "Prec.snow": 0.7642, "Prec.sofa": 0.6681, "Prec.table": 0.1994, "Prec.track": NaN, "Prec.train": 0.5078, "Prec.tree": 0.8093, "Prec.truck": 0.1436, "Prec.tvmonitor": 0.7083, "Prec.wall": 0.6178, "Prec.water": 0.8703, "Prec.window": 0.4473, "Prec.wood": 0.0755}
{"mode": "train", "epoch": 4, "iter": 2050, "lr": 0.00267, "memory": 17590, "data_time": 28.46015, "decode.loss_ce": 1.56446, "decode.acc_seg": 32.1786, "loss": 1.56446, "time": 29.35273}
{"mode": "train", "epoch": 4, "iter": 2100, "lr": 0.00261, "memory": 17590, "data_time": 0.01204, "decode.loss_ce": 1.53116, "decode.acc_seg": 32.86732, "loss": 1.53116, "time": 0.89998}
{"mode": "train", "epoch": 4, "iter": 2150, "lr": 0.00255, "memory": 17590, "data_time": 0.01246, "decode.loss_ce": 1.58255, "decode.acc_seg": 31.85897, "loss": 1.58255, "time": 0.9}
{"mode": "train", "epoch": 4, "iter": 2200, "lr": 0.00249, "memory": 17590, "data_time": 0.01245, "decode.loss_ce": 1.56, "decode.acc_seg": 33.4769, "loss": 1.56, "time": 0.9}
{"mode": "train", "epoch": 4, "iter": 2250, "lr": 0.00243, "memory": 17590, "data_time": 0.0128, "decode.loss_ce": 1.58245, "decode.acc_seg": 33.20251, "loss": 1.58245, "time": 0.89998}
{"mode": "train", "epoch": 4, "iter": 2300, "lr": 0.00237, "memory": 17590, "data_time": 0.01291, "decode.loss_ce": 1.50849, "decode.acc_seg": 32.76568, "loss": 1.50849, "time": 0.9}
{"mode": "train", "epoch": 4, "iter": 2350, "lr": 0.00231, "memory": 17590, "data_time": 0.01301, "decode.loss_ce": 1.65718, "decode.acc_seg": 34.09043, "loss": 1.65718, "time": 0.90001}
{"mode": "train", "epoch": 4, "iter": 2400, "lr": 0.00225, "memory": 17590, "data_time": 0.01304, "decode.loss_ce": 1.55266, "decode.acc_seg": 33.22812, "loss": 1.55266, "time": 0.90002}
{"mode": "train", "epoch": 4, "iter": 2450, "lr": 0.00219, "memory": 17590, "data_time": 0.0131, "decode.loss_ce": 1.51802, "decode.acc_seg": 33.80513, "loss": 1.51802, "time": 0.89997}
{"mode": "train", "epoch": 5, "iter": 2500, "lr": 0.00213, "memory": 17590, "data_time": 0.05887, "decode.loss_ce": 1.52776, "decode.acc_seg": 32.71125, "loss": 1.52776, "time": 0.94599}
{"mode": "train", "epoch": 5, "iter": 2550, "lr": 0.00207, "memory": 17590, "data_time": 0.01278, "decode.loss_ce": 1.46568, "decode.acc_seg": 32.44893, "loss": 1.46568, "time": 0.89996}
{"mode": "train", "epoch": 5, "iter": 2600, "lr": 0.00201, "memory": 17590, "data_time": 0.01297, "decode.loss_ce": 1.56087, "decode.acc_seg": 32.63184, "loss": 1.56087, "time": 0.9}
{"mode": "train", "epoch": 5, "iter": 2650, "lr": 0.00194, "memory": 17590, "data_time": 0.01306, "decode.loss_ce": 1.53454, "decode.acc_seg": 32.89482, "loss": 1.53454, "time": 0.89999}
{"mode": "train", "epoch": 5, "iter": 2700, "lr": 0.00188, "memory": 17590, "data_time": 0.01296, "decode.loss_ce": 1.44513, "decode.acc_seg": 32.65237, "loss": 1.44513, "time": 0.90018}
{"mode": "train", "epoch": 5, "iter": 2750, "lr": 0.00182, "memory": 17590, "data_time": 0.01298, "decode.loss_ce": 1.49885, "decode.acc_seg": 33.15207, "loss": 1.49885, "time": 0.89978}
{"mode": "train", "epoch": 5, "iter": 2800, "lr": 0.00176, "memory": 17590, "data_time": 0.01279, "decode.loss_ce": 1.54458, "decode.acc_seg": 34.0853, "loss": 1.54458, "time": 0.90003}
{"mode": "train", "epoch": 5, "iter": 2850, "lr": 0.0017, "memory": 17590, "data_time": 0.01296, "decode.loss_ce": 1.43739, "decode.acc_seg": 33.29555, "loss": 1.43739, "time": 0.90399}
{"mode": "train", "epoch": 5, "iter": 2900, "lr": 0.00163, "memory": 17590, "data_time": 0.01316, "decode.loss_ce": 1.46603, "decode.acc_seg": 32.94262, "loss": 1.46603, "time": 0.90001}
{"mode": "train", "epoch": 5, "iter": 2950, "lr": 0.00157, "memory": 17590, "data_time": 0.01323, "decode.loss_ce": 1.54283, "decode.acc_seg": 33.29152, "loss": 1.54283, "time": 0.89999}
{"mode": "train", "epoch": 5, "iter": 3000, "lr": 0.00151, "memory": 17590, "data_time": 0.01344, "decode.loss_ce": 1.50716, "decode.acc_seg": 33.63361, "loss": 1.50716, "time": 0.89998}
{"mode": "train", "epoch": 5, "iter": 3050, "lr": 0.00144, "memory": 17590, "data_time": 0.01339, "decode.loss_ce": 1.60368, "decode.acc_seg": 34.47484, "loss": 1.60368, "time": 0.90202}
{"mode": "train", "epoch": 5, "iter": 3100, "lr": 0.00138, "memory": 17590, "data_time": 0.01354, "decode.loss_ce": 1.52481, "decode.acc_seg": 33.89636, "loss": 1.52481, "time": 0.90001}
{"mode": "train", "epoch": 6, "iter": 3150, "lr": 0.00132, "memory": 17590, "data_time": 0.05894, "decode.loss_ce": 1.50712, "decode.acc_seg": 35.40424, "loss": 1.50712, "time": 0.94796}
{"mode": "train", "epoch": 6, "iter": 3200, "lr": 0.00125, "memory": 17590, "data_time": 0.01298, "decode.loss_ce": 1.49793, "decode.acc_seg": 33.16216, "loss": 1.49793, "time": 0.90002}
{"mode": "train", "epoch": 6, "iter": 3250, "lr": 0.00119, "memory": 17590, "data_time": 0.01297, "decode.loss_ce": 1.46972, "decode.acc_seg": 32.60676, "loss": 1.46972, "time": 0.89999}
{"mode": "train", "epoch": 6, "iter": 3300, "lr": 0.00112, "memory": 17590, "data_time": 0.01319, "decode.loss_ce": 1.5318, "decode.acc_seg": 34.14221, "loss": 1.5318, "time": 0.89998}
{"mode": "train", "epoch": 6, "iter": 3350, "lr": 0.00106, "memory": 17590, "data_time": 0.01347, "decode.loss_ce": 1.47947, "decode.acc_seg": 33.35913, "loss": 1.47947, "time": 0.90001}
{"mode": "train", "epoch": 6, "iter": 3400, "lr": 0.00099, "memory": 17590, "data_time": 0.01324, "decode.loss_ce": 1.47579, "decode.acc_seg": 35.15535, "loss": 1.47579, "time": 0.89999}
{"mode": "train", "epoch": 6, "iter": 3450, "lr": 0.00092, "memory": 17590, "data_time": 0.01308, "decode.loss_ce": 1.48516, "decode.acc_seg": 32.89298, "loss": 1.48516, "time": 0.89999}
{"mode": "train", "epoch": 6, "iter": 3500, "lr": 0.00086, "memory": 17590, "data_time": 0.01323, "decode.loss_ce": 1.57274, "decode.acc_seg": 33.49964, "loss": 1.57274, "time": 0.90001}
{"mode": "train", "epoch": 6, "iter": 3550, "lr": 0.00079, "memory": 17590, "data_time": 0.01336, "decode.loss_ce": 1.49782, "decode.acc_seg": 33.30596, "loss": 1.49782, "time": 0.90204}
{"mode": "train", "epoch": 6, "iter": 3600, "lr": 0.00072, "memory": 17590, "data_time": 0.01327, "decode.loss_ce": 1.46917, "decode.acc_seg": 32.43195, "loss": 1.46917, "time": 0.89995}
{"mode": "train", "epoch": 6, "iter": 3650, "lr": 0.00065, "memory": 17590, "data_time": 0.01334, "decode.loss_ce": 1.50302, "decode.acc_seg": 35.37784, "loss": 1.50302, "time": 0.90001}
{"mode": "train", "epoch": 6, "iter": 3700, "lr": 0.00058, "memory": 17590, "data_time": 0.01332, "decode.loss_ce": 1.46409, "decode.acc_seg": 34.21621, "loss": 1.46409, "time": 0.89999}
{"mode": "train", "epoch": 7, "iter": 3750, "lr": 0.00051, "memory": 17590, "data_time": 0.05968, "decode.loss_ce": 1.54937, "decode.acc_seg": 35.32496, "loss": 1.54937, "time": 0.94797}
{"mode": "train", "epoch": 7, "iter": 3800, "lr": 0.00043, "memory": 17590, "data_time": 0.01288, "decode.loss_ce": 1.43349, "decode.acc_seg": 33.94565, "loss": 1.43349, "time": 0.89999}
{"mode": "train", "epoch": 7, "iter": 3850, "lr": 0.00036, "memory": 17590, "data_time": 0.01297, "decode.loss_ce": 1.49103, "decode.acc_seg": 34.66976, "loss": 1.49103, "time": 0.90001}
{"mode": "train", "epoch": 7, "iter": 3900, "lr": 0.00028, "memory": 17590, "data_time": 0.01318, "decode.loss_ce": 1.50121, "decode.acc_seg": 34.33199, "loss": 1.50121, "time": 0.90198}
{"mode": "train", "epoch": 7, "iter": 3950, "lr": 0.0002, "memory": 17590, "data_time": 0.01333, "decode.loss_ce": 1.50714, "decode.acc_seg": 32.73, "loss": 1.50714, "time": 0.9}
{"mode": "train", "epoch": 7, "iter": 4000, "lr": 0.0001, "memory": 17590, "data_time": 0.01345, "decode.loss_ce": 1.4349, "decode.acc_seg": 34.27873, "loss": 1.4349, "time": 0.95054}
{"mode": "val", "epoch": 7, "iter": 5104, "lr": 0.0001, "aAcc": 0.5699, "mIoU": 0.3217, "mAcc": 0.5089, "mPrec": 0.49, "IoU.aeroplane": 0.3811, "IoU.bag": 0.0002, "IoU.bed": 0.0918, "IoU.bedclothes": 0.0777, "IoU.bench": 0.0, "IoU.bicycle": 0.5653, "IoU.bird": 0.6665, "IoU.boat": 0.368, "IoU.book": 0.0177, "IoU.bottle": 0.6142, "IoU.building": 0.1386, "IoU.bus": 0.7705, "IoU.cabinet": 0.0964, "IoU.car": 0.6625, "IoU.cat": 0.8103, "IoU.ceiling": 0.3106, "IoU.chair": 0.278, "IoU.cloth": 0.0561, "IoU.computer": 0.0631, "IoU.cow": 0.6784, "IoU.cup": 0.0193, "IoU.curtain": 0.3219, "IoU.dog": 0.7812, "IoU.door": 0.0856, "IoU.fence": 0.1831, "IoU.floor": 0.4834, "IoU.flower": 0.169, "IoU.food": 0.0691, "IoU.grass": 0.6058, "IoU.ground": 0.234, "IoU.horse": 0.5945, "IoU.keyboard": 0.6692, "IoU.light": 0.155, "IoU.motorbike": 0.6255, "IoU.mountain": 0.345, "IoU.mouse": 0.0, "IoU.person": 0.4765, "IoU.plate": 0.0077, "IoU.platform": 0.0, "IoU.pottedplant": 0.3579, "IoU.road": 0.4175, "IoU.rock": 0.3038, "IoU.sheep": 0.7011, "IoU.shelves": 0.0584, "IoU.sidewalk": 0.1121, "IoU.sign": 0.2503, "IoU.sky": 0.5704, "IoU.snow": 0.4665, "IoU.sofa": 0.3714, "IoU.table": 0.1505, "IoU.track": 0.0, "IoU.train": 0.4621, "IoU.tree": 0.4853, "IoU.truck": 0.1083, "IoU.tvmonitor": 0.4637, "IoU.wall": 0.3323, "IoU.water": 0.6722, "IoU.window": 0.1544, "IoU.wood": 0.0706, "Acc.aeroplane": 0.9645, "Acc.bag": 0.0002, "Acc.bed": 0.3931, "Acc.bedclothes": 0.0841, "Acc.bench": 0.0, "Acc.bicycle": 0.8981, "Acc.bird": 0.9537, "Acc.boat": 0.8585, "Acc.book": 0.0178, "Acc.bottle": 0.7851, "Acc.building": 0.1417, "Acc.bus": 0.9148, "Acc.cabinet": 0.2555, "Acc.car": 0.9086, "Acc.cat": 0.9583, "Acc.ceiling": 0.7357, "Acc.chair": 0.3595, "Acc.cloth": 0.2811, "Acc.computer": 0.2155, "Acc.cow": 0.9165, "Acc.cup": 0.0252, "Acc.curtain": 0.4024, "Acc.dog": 0.9049, "Acc.door": 0.5639, "Acc.fence": 0.2099, "Acc.floor": 0.6816, "Acc.flower": 0.4276, "Acc.food": 0.864, "Acc.grass": 0.6912, "Acc.ground": 0.4103, "Acc.horse": 0.9317, "Acc.keyboard": 0.7472, "Acc.light": 0.5689, "Acc.motorbike": 0.8161, "Acc.mountain": 0.5016, "Acc.mouse": 0.0, "Acc.person": 0.5304, "Acc.plate": 0.0086, "Acc.platform": 0.0, "Acc.pottedplant": 0.7479, "Acc.road": 0.606, "Acc.rock": 0.6448, "Acc.sheep": 0.8848, "Acc.shelves": 0.0656, "Acc.sidewalk": 0.6379, "Acc.sign": 0.4254, "Acc.sky": 0.5803, "Acc.snow": 0.5889, "Acc.sofa": 0.4516, "Acc.table": 0.432, "Acc.track": 0.0, "Acc.train": 0.9147, "Acc.tree": 0.5411, "Acc.truck": 0.2627, "Acc.tvmonitor": 0.5506, "Acc.wall": 0.4226, "Acc.water": 0.7552, "Acc.window": 0.1854, "Acc.wood": 0.4023, "Prec.aeroplane": 0.3865, "Prec.bag": 0.6676, "Prec.bed": 0.1069, "Prec.bedclothes": 0.5065, "Prec.bench": 0.0081, "Prec.bicycle": 0.604, "Prec.bird": 0.6888, "Prec.boat": 0.3917, "Prec.book": 0.8345, "Prec.bottle": 0.7383, "Prec.building": 0.8625, "Prec.bus": 0.8301, "Prec.cabinet": 0.134, "Prec.car": 0.7098, "Prec.cat": 0.8399, "Prec.ceiling": 0.3496, "Prec.chair": 0.5508, "Prec.cloth": 0.0655, "Prec.computer": 0.0819, "Prec.cow": 0.7231, "Prec.cup": 0.0765, "Prec.curtain": 0.6167, "Prec.dog": 0.8511, "Prec.door": 0.0917, "Prec.fence": 0.5892, "Prec.floor": 0.6243, "Prec.flower": 0.2184, "Prec.food": 0.0699, "Prec.grass": 0.8306, "Prec.ground": 0.3527, "Prec.horse": 0.6215, "Prec.keyboard": 0.8652, "Prec.light": 0.1756, "Prec.motorbike": 0.7281, "Prec.mountain": 0.5251, "Prec.mouse": 0.0, "Prec.person": 0.8245, "Prec.plate": 0.0643, "Prec.platform": NaN, "Prec.pottedplant": 0.407, "Prec.road": 0.573, "Prec.rock": 0.3649, "Prec.sheep": 0.7715, "Prec.shelves": 0.3493, "Prec.sidewalk": 0.1197, "Prec.sign": 0.3782, "Prec.sky": 0.971, "Prec.snow": 0.6918, "Prec.sofa": 0.6763, "Prec.table": 0.1876, "Prec.track": NaN, "Prec.train": 0.483, "Prec.tree": 0.8246, "Prec.truck": 0.1555, "Prec.tvmonitor": 0.746, "Prec.wall": 0.6086, "Prec.water": 0.8595, "Prec.window": 0.4801, "Prec.wood": 0.0789}
