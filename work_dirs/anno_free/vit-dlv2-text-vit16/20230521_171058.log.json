{"env_info": "sys.platform: linux\nPython: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]\nCUDA available: True\nGPU 0: NVIDIA GeForce RTX 3090\nCUDA_HOME: /usr/local/cuda\nNVCC: Build cuda_11.8.r11.8/compiler.31833905_0\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\nPyTorch: 1.9.0+cu111\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.10.0+cu111\nOpenCV: 4.7.0\nMMCV: 1.4.0\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.1\nMMSegmentation: 0.20.2+03c38b7", "seed": 1314192054, "exp_name": "maskclip_plus_vit16_deeplabv2_r101-d8_class_weight_480x480_4k_pascal_context_59.py", "mmseg_version": "0.20.2+03c38b7", "config": "norm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    type='EncoderDecoder',\n    pretrained='open-mmlab://resnet101_v1c',\n    backbone=dict(\n        type='ResNetV1c',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        dilations=(1, 1, 2, 4),\n        strides=(1, 2, 1, 1),\n        norm_cfg=dict(type='SyncBN', requires_grad=True),\n        norm_eval=False,\n        style='pytorch',\n        contract_dilation=True,\n        pretrained='open-mmlab://resnet101_v1c'),\n    decode_head=dict(\n        type='MaskClipPlusTextHead',\n        vit=True,\n        in_channels=2048,\n        channels=512,\n        num_classes=59,\n        dropout_ratio=0,\n        norm_cfg=dict(type='SyncBN', requires_grad=True),\n        loss_decode=dict(\n            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n        decode_module_cfg=dict(\n            type='ASPPHeadV2',\n            dilations=(6, 12, 18, 24),\n            in_channels=2048,\n            channels=512,\n            num_classes=59,\n            dropout_ratio=0,\n            norm_cfg=dict(type='SyncBN', requires_grad=True),\n            loss_decode=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            init_cfg=None),\n        text_categories=59,\n        text_channels=512,\n        clip_channels=768,\n        text_embeddings_path='pretrain/context_ViT16_clip_text.pth',\n        text_features_path='pretrain/context_ViT16_clip_text_features.pth',\n        tau=1,\n        cls_bg=False,\n        norm_feat=False,\n        clip_unlabeled_cats=[\n            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n            19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n            36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n            53, 54, 55, 56, 57, 58\n        ],\n        clip_cfg=dict(\n            type='VisionTransformer',\n            img_size=(224, 224),\n            patch_size=16,\n            patch_bias=False,\n            in_channels=3,\n            embed_dims=768,\n            num_layers=12,\n            num_heads=12,\n            mlp_ratio=4,\n            out_indices=-1,\n            qkv_bias=True,\n            drop_rate=0.0,\n            attn_drop_rate=0.0,\n            drop_path_rate=0.0,\n            with_cls_token=True,\n            output_cls_token=False,\n            norm_cfg=dict(type='LN', eps=1e-06),\n            act_cfg=dict(type='GELU'),\n            patch_norm=False,\n            pre_norm=True,\n            final_norm=True,\n            return_qkv=True,\n            interpolate_mode='bicubic',\n            num_fcs=2,\n            norm_eval=False),\n        clip_weights_path='pretrain/ViT16_clip_weights.pth',\n        reset_counter=True,\n        start_clip_guided=(1, -1),\n        start_self_train=(-1, -1)),\n    feed_img_to_decode_head=True,\n    train_cfg=dict(),\n    test_cfg=dict(mode='whole'))\ndataset_type = 'PascalContextDataset59'\ndata_root = 'data/VOCdevkit/VOC2010/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nimg_scale = (520, 520)\ncrop_size = (480, 480)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='LoadAnnotations',\n        reduce_zero_label=True,\n        suppress_labels=[\n            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n            19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n            36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n            53, 54, 55, 56, 57, 58\n        ]),\n    dict(type='Resize', img_scale=(520, 520), ratio_range=(0.5, 2.0)),\n    dict(type='RandomCrop', crop_size=(480, 480), cat_max_ratio=0.75),\n    dict(type='RandomFlip', prob=0.5),\n    dict(type='PhotoMetricDistortion'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size=(480, 480), pad_val=0, seg_pad_val=255),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(520, 520),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    train=dict(\n        type='PascalContextDataset59',\n        data_root='data/VOCdevkit/VOC2010/',\n        img_dir='JPEGImages',\n        ann_dir='SegmentationClassContext',\n        split='ImageSets/SegmentationContext/train.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='LoadAnnotations',\n                reduce_zero_label=True,\n                suppress_labels=[\n                    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n                    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n                    47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58\n                ]),\n            dict(type='Resize', img_scale=(520, 520), ratio_range=(0.5, 2.0)),\n            dict(type='RandomCrop', crop_size=(480, 480), cat_max_ratio=0.75),\n            dict(type='RandomFlip', prob=0.5),\n            dict(type='PhotoMetricDistortion'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size=(480, 480), pad_val=0, seg_pad_val=255),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n        ]),\n    val=dict(\n        type='PascalContextDataset59',\n        data_root='data/VOCdevkit/VOC2010/',\n        img_dir='JPEGImages',\n        ann_dir='SegmentationClassContext',\n        split='ImageSets/SegmentationContext/val.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(520, 520),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='PascalContextDataset59',\n        data_root='data/VOCdevkit/VOC2010/',\n        img_dir='JPEGImages',\n        ann_dir='SegmentationClassContext',\n        split='ImageSets/SegmentationContext/val.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(520, 520),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nlog_config = dict(\n    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\noptimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.00025)\noptimizer_config = dict()\nlr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\nrunner = dict(type='IterBasedRunner', max_iters=4000)\ncheckpoint_config = dict(by_epoch=False, interval=2000)\nevaluation = dict(interval=2000, metric='mIoU', pre_eval=True)\nsuppress_labels = [\n    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n    40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58\n]\nfind_unused_parameters = True\nwork_dir = 'work_dirs/anno_free/vit-dlv2-text-vit16'\ngpu_ids = range(0, 1)\nauto_resume = False\nseed = 1314192054\n", "CLASSES": ["aeroplane", "bag", "bed", "bedclothes", "bench", "bicycle", "bird", "boat", "book", "bottle", "building", "bus", "cabinet", "car", "cat", "ceiling", "chair", "cloth", "computer", "cow", "cup", "curtain", "dog", "door", "fence", "floor", "flower", "food", "grass", "ground", "horse", "keyboard", "light", "motorbike", "mountain", "mouse", "person", "plate", "platform", "pottedplant", "road", "rock", "sheep", "shelves", "sidewalk", "sign", "sky", "snow", "sofa", "table", "track", "train", "tree", "truck", "tvmonitor", "wall", "water", "window", "wood"], "PALETTE": [[180, 120, 120], [6, 230, 230], [80, 50, 50], [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255], [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7], [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82], [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3], [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255], [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220], [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224], [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255], [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7], [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153], [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255], [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0], [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255], [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255]]}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00495, "memory": 17588, "data_time": 0.02347, "decode.loss_ce": 2.92404, "decode.acc_seg": 3.1218, "loss": 2.92404, "time": 0.9795}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.00489, "memory": 17588, "data_time": 0.01228, "decode.loss_ce": 2.69116, "decode.acc_seg": 11.11101, "loss": 2.69116, "time": 0.90393}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.00484, "memory": 17588, "data_time": 0.0126, "decode.loss_ce": 2.32242, "decode.acc_seg": 17.99999, "loss": 2.32242, "time": 0.89999}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00478, "memory": 17588, "data_time": 0.01283, "decode.loss_ce": 2.01754, "decode.acc_seg": 21.73872, "loss": 2.01754, "time": 0.89996}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.00472, "memory": 17588, "data_time": 0.01279, "decode.loss_ce": 2.03933, "decode.acc_seg": 24.26683, "loss": 2.03933, "time": 0.90003}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.00467, "memory": 17588, "data_time": 0.01298, "decode.loss_ce": 1.89443, "decode.acc_seg": 25.42045, "loss": 1.89443, "time": 0.89998}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.00461, "memory": 17588, "data_time": 0.01298, "decode.loss_ce": 1.83141, "decode.acc_seg": 26.84674, "loss": 1.83141, "time": 0.90002}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.00456, "memory": 17588, "data_time": 0.01318, "decode.loss_ce": 1.85994, "decode.acc_seg": 26.00445, "loss": 1.85994, "time": 0.89997}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.0045, "memory": 17588, "data_time": 0.01316, "decode.loss_ce": 1.79835, "decode.acc_seg": 26.86679, "loss": 1.79835, "time": 0.9}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.00445, "memory": 17588, "data_time": 0.01326, "decode.loss_ce": 1.82575, "decode.acc_seg": 28.02277, "loss": 1.82575, "time": 0.90001}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.00439, "memory": 17588, "data_time": 0.01351, "decode.loss_ce": 1.82754, "decode.acc_seg": 27.7193, "loss": 1.82754, "time": 0.89995}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.00433, "memory": 17588, "data_time": 0.014, "decode.loss_ce": 1.79601, "decode.acc_seg": 28.15031, "loss": 1.79601, "time": 0.90002}
{"mode": "train", "epoch": 2, "iter": 650, "lr": 0.00428, "memory": 17588, "data_time": 0.06022, "decode.loss_ce": 1.71496, "decode.acc_seg": 29.14651, "loss": 1.71496, "time": 0.95001}
{"mode": "train", "epoch": 2, "iter": 700, "lr": 0.00422, "memory": 17588, "data_time": 0.01319, "decode.loss_ce": 1.71421, "decode.acc_seg": 30.213, "loss": 1.71421, "time": 0.89995}
{"mode": "train", "epoch": 2, "iter": 750, "lr": 0.00417, "memory": 17588, "data_time": 0.01317, "decode.loss_ce": 1.74236, "decode.acc_seg": 29.97022, "loss": 1.74236, "time": 0.9}
{"mode": "train", "epoch": 2, "iter": 800, "lr": 0.00411, "memory": 17588, "data_time": 0.0132, "decode.loss_ce": 1.73887, "decode.acc_seg": 29.72546, "loss": 1.73887, "time": 0.89999}
{"mode": "train", "epoch": 2, "iter": 850, "lr": 0.00405, "memory": 17588, "data_time": 0.01356, "decode.loss_ce": 1.75497, "decode.acc_seg": 29.48777, "loss": 1.75497, "time": 0.90001}
{"mode": "train", "epoch": 2, "iter": 900, "lr": 0.004, "memory": 17588, "data_time": 0.0138, "decode.loss_ce": 1.67156, "decode.acc_seg": 29.80525, "loss": 1.67156, "time": 0.89997}
{"mode": "train", "epoch": 2, "iter": 950, "lr": 0.00394, "memory": 17588, "data_time": 0.01406, "decode.loss_ce": 1.68245, "decode.acc_seg": 29.09585, "loss": 1.68245, "time": 0.9}
{"mode": "train", "epoch": 2, "iter": 1000, "lr": 0.00388, "memory": 17588, "data_time": 0.01415, "decode.loss_ce": 1.79045, "decode.acc_seg": 30.88878, "loss": 1.79045, "time": 0.90002}
{"mode": "train", "epoch": 2, "iter": 1050, "lr": 0.00383, "memory": 17588, "data_time": 0.01414, "decode.loss_ce": 1.68266, "decode.acc_seg": 30.78372, "loss": 1.68266, "time": 0.89996}
{"mode": "train", "epoch": 2, "iter": 1100, "lr": 0.00377, "memory": 17588, "data_time": 0.01405, "decode.loss_ce": 1.64803, "decode.acc_seg": 29.44857, "loss": 1.64803, "time": 0.89998}
{"mode": "train", "epoch": 2, "iter": 1150, "lr": 0.00371, "memory": 17588, "data_time": 0.01434, "decode.loss_ce": 1.58111, "decode.acc_seg": 29.51324, "loss": 1.58111, "time": 0.90002}
{"mode": "train", "epoch": 2, "iter": 1200, "lr": 0.00366, "memory": 17588, "data_time": 0.01408, "decode.loss_ce": 1.6019, "decode.acc_seg": 31.0913, "loss": 1.6019, "time": 0.89997}
{"mode": "train", "epoch": 3, "iter": 1250, "lr": 0.0036, "memory": 17588, "data_time": 0.06018, "decode.loss_ce": 1.60821, "decode.acc_seg": 32.48746, "loss": 1.60821, "time": 0.94599}
{"mode": "train", "epoch": 3, "iter": 1300, "lr": 0.00354, "memory": 17588, "data_time": 0.01332, "decode.loss_ce": 1.60625, "decode.acc_seg": 32.98117, "loss": 1.60625, "time": 0.90003}
{"mode": "train", "epoch": 3, "iter": 1350, "lr": 0.00348, "memory": 17588, "data_time": 0.01357, "decode.loss_ce": 1.60595, "decode.acc_seg": 31.52101, "loss": 1.60595, "time": 0.89998}
{"mode": "train", "epoch": 3, "iter": 1400, "lr": 0.00343, "memory": 17588, "data_time": 0.01371, "decode.loss_ce": 1.71103, "decode.acc_seg": 31.53294, "loss": 1.71103, "time": 0.90001}
{"mode": "train", "epoch": 3, "iter": 1450, "lr": 0.00337, "memory": 17588, "data_time": 0.01373, "decode.loss_ce": 1.63261, "decode.acc_seg": 31.21718, "loss": 1.63261, "time": 0.89998}
{"mode": "train", "epoch": 3, "iter": 1500, "lr": 0.00331, "memory": 17588, "data_time": 0.01382, "decode.loss_ce": 1.55025, "decode.acc_seg": 31.50003, "loss": 1.55025, "time": 0.9}
{"mode": "train", "epoch": 3, "iter": 1550, "lr": 0.00325, "memory": 17588, "data_time": 0.01402, "decode.loss_ce": 1.5621, "decode.acc_seg": 30.82175, "loss": 1.5621, "time": 0.89998}
{"mode": "train", "epoch": 3, "iter": 1600, "lr": 0.0032, "memory": 17588, "data_time": 0.0141, "decode.loss_ce": 1.63926, "decode.acc_seg": 31.93146, "loss": 1.63926, "time": 0.9}
{"mode": "train", "epoch": 3, "iter": 1650, "lr": 0.00314, "memory": 17588, "data_time": 0.01419, "decode.loss_ce": 1.55939, "decode.acc_seg": 31.70945, "loss": 1.55939, "time": 0.89999}
{"mode": "train", "epoch": 3, "iter": 1700, "lr": 0.00308, "memory": 17588, "data_time": 0.01437, "decode.loss_ce": 1.54924, "decode.acc_seg": 31.79948, "loss": 1.54924, "time": 0.89999}
{"mode": "train", "epoch": 3, "iter": 1750, "lr": 0.00302, "memory": 17588, "data_time": 0.01457, "decode.loss_ce": 1.60504, "decode.acc_seg": 32.5654, "loss": 1.60504, "time": 0.90399}
{"mode": "train", "epoch": 3, "iter": 1800, "lr": 0.00296, "memory": 17588, "data_time": 0.01464, "decode.loss_ce": 1.56707, "decode.acc_seg": 32.14824, "loss": 1.56707, "time": 0.90001}
{"mode": "train", "epoch": 3, "iter": 1850, "lr": 0.0029, "memory": 17588, "data_time": 0.01469, "decode.loss_ce": 1.60555, "decode.acc_seg": 32.53147, "loss": 1.60555, "time": 0.89996}
{"mode": "train", "epoch": 4, "iter": 1900, "lr": 0.00284, "memory": 17588, "data_time": 0.06005, "decode.loss_ce": 1.58046, "decode.acc_seg": 32.06292, "loss": 1.58046, "time": 0.94604}
{"mode": "train", "epoch": 4, "iter": 1950, "lr": 0.00279, "memory": 17588, "data_time": 0.01397, "decode.loss_ce": 1.64169, "decode.acc_seg": 32.96886, "loss": 1.64169, "time": 0.89994}
{"mode": "train", "epoch": 4, "iter": 2000, "lr": 0.00273, "memory": 17588, "data_time": 0.01408, "decode.loss_ce": 1.54693, "decode.acc_seg": 31.30517, "loss": 1.54693, "time": 0.94781}
{"mode": "val", "epoch": 4, "iter": 5104, "lr": 0.00273, "aAcc": 0.5728, "mIoU": 0.3191, "mAcc": 0.4947, "mPrec": 0.4876, "IoU.aeroplane": 0.4163, "IoU.bag": 0.0003, "IoU.bed": 0.0874, "IoU.bedclothes": 0.0877, "IoU.bench": 0.0, "IoU.bicycle": 0.5324, "IoU.bird": 0.6601, "IoU.boat": 0.3522, "IoU.book": 0.0021, "IoU.bottle": 0.6048, "IoU.building": 0.1819, "IoU.bus": 0.7714, "IoU.cabinet": 0.0808, "IoU.car": 0.6879, "IoU.cat": 0.8025, "IoU.ceiling": 0.3205, "IoU.chair": 0.2631, "IoU.cloth": 0.0613, "IoU.computer": 0.057, "IoU.cow": 0.6913, "IoU.cup": 0.0292, "IoU.curtain": 0.2625, "IoU.dog": 0.7895, "IoU.door": 0.0936, "IoU.fence": 0.1698, "IoU.floor": 0.4392, "IoU.flower": 0.1536, "IoU.food": 0.0762, "IoU.grass": 0.6019, "IoU.ground": 0.2316, "IoU.horse": 0.5785, "IoU.keyboard": 0.671, "IoU.light": 0.1625, "IoU.motorbike": 0.6213, "IoU.mountain": 0.3468, "IoU.mouse": 0.0, "IoU.person": 0.4933, "IoU.plate": 0.0007, "IoU.platform": 0.0, "IoU.pottedplant": 0.3754, "IoU.road": 0.4146, "IoU.rock": 0.2987, "IoU.sheep": 0.7057, "IoU.shelves": 0.0055, "IoU.sidewalk": 0.1068, "IoU.sign": 0.2293, "IoU.sky": 0.584, "IoU.snow": 0.4648, "IoU.sofa": 0.359, "IoU.table": 0.1571, "IoU.track": 0.0, "IoU.train": 0.4553, "IoU.tree": 0.4693, "IoU.truck": 0.0938, "IoU.tvmonitor": 0.5158, "IoU.wall": 0.3418, "IoU.water": 0.6352, "IoU.window": 0.1676, "IoU.wood": 0.0624, "Acc.aeroplane": 0.9594, "Acc.bag": 0.0003, "Acc.bed": 0.3587, "Acc.bedclothes": 0.0973, "Acc.bench": 0.0, "Acc.bicycle": 0.9372, "Acc.bird": 0.9413, "Acc.boat": 0.8606, "Acc.book": 0.0021, "Acc.bottle": 0.7347, "Acc.building": 0.1895, "Acc.bus": 0.949, "Acc.cabinet": 0.206, "Acc.car": 0.9086, "Acc.cat": 0.9662, "Acc.ceiling": 0.6325, "Acc.chair": 0.3329, "Acc.cloth": 0.3186, "Acc.computer": 0.1386, "Acc.cow": 0.8864, "Acc.cup": 0.0411, "Acc.curtain": 0.3086, "Acc.dog": 0.9224, "Acc.door": 0.5241, "Acc.fence": 0.2056, "Acc.floor": 0.5876, "Acc.flower": 0.2977, "Acc.food": 0.8332, "Acc.grass": 0.7367, "Acc.ground": 0.4129, "Acc.horse": 0.9428, "Acc.keyboard": 0.8, "Acc.light": 0.4546, "Acc.motorbike": 0.773, "Acc.mountain": 0.5306, "Acc.mouse": 0.0, "Acc.person": 0.5422, "Acc.plate": 0.0008, "Acc.platform": 0.0, "Acc.pottedplant": 0.7719, "Acc.road": 0.639, "Acc.rock": 0.5927, "Acc.sheep": 0.8788, "Acc.shelves": 0.0056, "Acc.sidewalk": 0.6386, "Acc.sign": 0.2999, "Acc.sky": 0.5976, "Acc.snow": 0.57, "Acc.sofa": 0.4587, "Acc.table": 0.4467, "Acc.track": 0.0, "Acc.train": 0.9117, "Acc.tree": 0.5239, "Acc.truck": 0.1681, "Acc.tvmonitor": 0.6242, "Acc.wall": 0.4221, "Acc.water": 0.6965, "Acc.window": 0.2048, "Acc.wood": 0.3997, "Prec.aeroplane": 0.4238, "Prec.bag": 0.9797, "Prec.bed": 0.1036, "Prec.bedclothes": 0.4708, "Prec.bench": 0.0, "Prec.bicycle": 0.5521, "Prec.bird": 0.6885, "Prec.boat": 0.3735, "Prec.book": 1.0, "Prec.bottle": 0.7738, "Prec.building": 0.8201, "Prec.bus": 0.8048, "Prec.cabinet": 0.1174, "Prec.car": 0.7391, "Prec.cat": 0.8257, "Prec.ceiling": 0.3938, "Prec.chair": 0.5566, "Prec.cloth": 0.0705, "Prec.computer": 0.0882, "Prec.cow": 0.7585, "Prec.cup": 0.0917, "Prec.curtain": 0.6375, "Prec.dog": 0.8457, "Prec.door": 0.1022, "Prec.fence": 0.4942, "Prec.floor": 0.6349, "Prec.flower": 0.2408, "Prec.food": 0.0774, "Prec.grass": 0.7669, "Prec.ground": 0.3454, "Prec.horse": 0.5995, "Prec.keyboard": 0.8062, "Prec.light": 0.2018, "Prec.motorbike": 0.7599, "Prec.mountain": 0.5003, "Prec.mouse": 0.0, "Prec.person": 0.8453, "Prec.plate": 0.0047, "Prec.platform": NaN, "Prec.pottedplant": 0.4222, "Prec.road": 0.5415, "Prec.rock": 0.3758, "Prec.sheep": 0.7817, "Prec.shelves": 0.2741, "Prec.sidewalk": 0.1136, "Prec.sign": 0.4934, "Prec.sky": 0.9624, "Prec.snow": 0.7157, "Prec.sofa": 0.6229, "Prec.table": 0.1951, "Prec.track": 0.0, "Prec.train": 0.4763, "Prec.tree": 0.8181, "Prec.truck": 0.1749, "Prec.tvmonitor": 0.7482, "Prec.wall": 0.6424, "Prec.water": 0.8784, "Prec.window": 0.4797, "Prec.wood": 0.0689}
{"mode": "train", "epoch": 4, "iter": 2050, "lr": 0.00267, "memory": 17588, "data_time": 27.27732, "decode.loss_ce": 1.56972, "decode.acc_seg": 33.21081, "loss": 1.56972, "time": 28.1702}
{"mode": "train", "epoch": 4, "iter": 2100, "lr": 0.00261, "memory": 17588, "data_time": 0.01271, "decode.loss_ce": 1.52222, "decode.acc_seg": 32.96515, "loss": 1.52222, "time": 0.89998}
{"mode": "train", "epoch": 4, "iter": 2150, "lr": 0.00255, "memory": 17588, "data_time": 0.013, "decode.loss_ce": 1.51924, "decode.acc_seg": 32.83515, "loss": 1.51924, "time": 0.89999}
{"mode": "train", "epoch": 4, "iter": 2200, "lr": 0.00249, "memory": 17588, "data_time": 0.01324, "decode.loss_ce": 1.53287, "decode.acc_seg": 32.92455, "loss": 1.53287, "time": 0.89999}
{"mode": "train", "epoch": 4, "iter": 2250, "lr": 0.00243, "memory": 17588, "data_time": 0.01331, "decode.loss_ce": 1.52946, "decode.acc_seg": 33.32454, "loss": 1.52946, "time": 0.9}
{"mode": "train", "epoch": 4, "iter": 2300, "lr": 0.00237, "memory": 17588, "data_time": 0.01345, "decode.loss_ce": 1.5245, "decode.acc_seg": 33.59194, "loss": 1.5245, "time": 0.89999}
{"mode": "train", "epoch": 4, "iter": 2350, "lr": 0.00231, "memory": 17588, "data_time": 0.01367, "decode.loss_ce": 1.61329, "decode.acc_seg": 33.90089, "loss": 1.61329, "time": 0.90198}
{"mode": "train", "epoch": 4, "iter": 2400, "lr": 0.00225, "memory": 17588, "data_time": 0.01381, "decode.loss_ce": 1.52866, "decode.acc_seg": 31.66761, "loss": 1.52866, "time": 0.89999}
{"mode": "train", "epoch": 4, "iter": 2450, "lr": 0.00219, "memory": 17588, "data_time": 0.01396, "decode.loss_ce": 1.49912, "decode.acc_seg": 32.97751, "loss": 1.49912, "time": 0.89999}
{"mode": "train", "epoch": 5, "iter": 2500, "lr": 0.00213, "memory": 17588, "data_time": 0.05916, "decode.loss_ce": 1.55566, "decode.acc_seg": 32.76757, "loss": 1.55566, "time": 0.94598}
{"mode": "train", "epoch": 5, "iter": 2550, "lr": 0.00207, "memory": 17588, "data_time": 0.01314, "decode.loss_ce": 1.51256, "decode.acc_seg": 33.83313, "loss": 1.51256, "time": 0.9}
{"mode": "train", "epoch": 5, "iter": 2600, "lr": 0.00201, "memory": 17588, "data_time": 0.01345, "decode.loss_ce": 1.53464, "decode.acc_seg": 33.7121, "loss": 1.53464, "time": 0.9}
{"mode": "train", "epoch": 5, "iter": 2650, "lr": 0.00194, "memory": 17588, "data_time": 0.01346, "decode.loss_ce": 1.53246, "decode.acc_seg": 34.04876, "loss": 1.53246, "time": 0.89998}
{"mode": "train", "epoch": 5, "iter": 2700, "lr": 0.00188, "memory": 17588, "data_time": 0.01369, "decode.loss_ce": 1.50089, "decode.acc_seg": 34.29108, "loss": 1.50089, "time": 0.90001}
{"mode": "train", "epoch": 5, "iter": 2750, "lr": 0.00182, "memory": 17588, "data_time": 0.01385, "decode.loss_ce": 1.50325, "decode.acc_seg": 33.55766, "loss": 1.50325, "time": 0.89998}
{"mode": "train", "epoch": 5, "iter": 2800, "lr": 0.00176, "memory": 17588, "data_time": 0.01425, "decode.loss_ce": 1.43892, "decode.acc_seg": 32.48843, "loss": 1.43892, "time": 0.9}
{"mode": "train", "epoch": 5, "iter": 2850, "lr": 0.0017, "memory": 17588, "data_time": 0.01409, "decode.loss_ce": 1.4768, "decode.acc_seg": 33.79528, "loss": 1.4768, "time": 0.9}
{"mode": "train", "epoch": 5, "iter": 2900, "lr": 0.00163, "memory": 17588, "data_time": 0.01422, "decode.loss_ce": 1.55909, "decode.acc_seg": 33.46866, "loss": 1.55909, "time": 0.89998}
{"mode": "train", "epoch": 5, "iter": 2950, "lr": 0.00157, "memory": 17588, "data_time": 0.01455, "decode.loss_ce": 1.52205, "decode.acc_seg": 35.13066, "loss": 1.52205, "time": 0.90002}
{"mode": "train", "epoch": 5, "iter": 3000, "lr": 0.00151, "memory": 17588, "data_time": 0.01468, "decode.loss_ce": 1.52831, "decode.acc_seg": 34.35683, "loss": 1.52831, "time": 0.9}
{"mode": "train", "epoch": 5, "iter": 3050, "lr": 0.00144, "memory": 17588, "data_time": 0.01453, "decode.loss_ce": 1.48903, "decode.acc_seg": 31.66661, "loss": 1.48903, "time": 0.89998}
{"mode": "train", "epoch": 5, "iter": 3100, "lr": 0.00138, "memory": 17588, "data_time": 0.01454, "decode.loss_ce": 1.58653, "decode.acc_seg": 32.91538, "loss": 1.58653, "time": 0.90003}
{"mode": "train", "epoch": 6, "iter": 3150, "lr": 0.00132, "memory": 17588, "data_time": 0.05951, "decode.loss_ce": 1.45831, "decode.acc_seg": 32.58257, "loss": 1.45831, "time": 0.94595}
{"mode": "train", "epoch": 6, "iter": 3200, "lr": 0.00125, "memory": 17588, "data_time": 0.01342, "decode.loss_ce": 1.50211, "decode.acc_seg": 33.90584, "loss": 1.50211, "time": 0.9}
{"mode": "train", "epoch": 6, "iter": 3250, "lr": 0.00119, "memory": 17588, "data_time": 0.01351, "decode.loss_ce": 1.51341, "decode.acc_seg": 33.14148, "loss": 1.51341, "time": 0.90001}
{"mode": "train", "epoch": 6, "iter": 3300, "lr": 0.00112, "memory": 17588, "data_time": 0.01359, "decode.loss_ce": 1.4952, "decode.acc_seg": 33.10137, "loss": 1.4952, "time": 0.89998}
{"mode": "train", "epoch": 6, "iter": 3350, "lr": 0.00106, "memory": 17588, "data_time": 0.01402, "decode.loss_ce": 1.52876, "decode.acc_seg": 35.02538, "loss": 1.52876, "time": 0.90199}
{"mode": "train", "epoch": 6, "iter": 3400, "lr": 0.00099, "memory": 17588, "data_time": 0.0142, "decode.loss_ce": 1.452, "decode.acc_seg": 33.41793, "loss": 1.452, "time": 0.89999}
{"mode": "train", "epoch": 6, "iter": 3450, "lr": 0.00092, "memory": 17588, "data_time": 0.01426, "decode.loss_ce": 1.51404, "decode.acc_seg": 31.62446, "loss": 1.51404, "time": 0.89998}
{"mode": "train", "epoch": 6, "iter": 3500, "lr": 0.00086, "memory": 17588, "data_time": 0.01441, "decode.loss_ce": 1.51418, "decode.acc_seg": 34.21366, "loss": 1.51418, "time": 0.9}
{"mode": "train", "epoch": 6, "iter": 3550, "lr": 0.00079, "memory": 17588, "data_time": 0.01412, "decode.loss_ce": 1.51438, "decode.acc_seg": 35.14481, "loss": 1.51438, "time": 0.90002}
{"mode": "train", "epoch": 6, "iter": 3600, "lr": 0.00072, "memory": 17588, "data_time": 0.01417, "decode.loss_ce": 1.54365, "decode.acc_seg": 35.28314, "loss": 1.54365, "time": 0.89997}
{"mode": "train", "epoch": 6, "iter": 3650, "lr": 0.00065, "memory": 17588, "data_time": 0.01422, "decode.loss_ce": 1.45272, "decode.acc_seg": 34.16637, "loss": 1.45272, "time": 0.9}
{"mode": "train", "epoch": 6, "iter": 3700, "lr": 0.00058, "memory": 17588, "data_time": 0.01427, "decode.loss_ce": 1.50911, "decode.acc_seg": 33.72795, "loss": 1.50911, "time": 0.89997}
{"mode": "train", "epoch": 7, "iter": 3750, "lr": 0.00051, "memory": 17588, "data_time": 0.05974, "decode.loss_ce": 1.45011, "decode.acc_seg": 33.79717, "loss": 1.45011, "time": 0.94598}
{"mode": "train", "epoch": 7, "iter": 3800, "lr": 0.00043, "memory": 17588, "data_time": 0.01339, "decode.loss_ce": 1.5154, "decode.acc_seg": 34.34391, "loss": 1.5154, "time": 0.90002}
{"mode": "train", "epoch": 7, "iter": 3850, "lr": 0.00036, "memory": 17588, "data_time": 0.01376, "decode.loss_ce": 1.52644, "decode.acc_seg": 34.94469, "loss": 1.52644, "time": 0.89996}
{"mode": "train", "epoch": 7, "iter": 3900, "lr": 0.00028, "memory": 17588, "data_time": 0.01383, "decode.loss_ce": 1.5536, "decode.acc_seg": 34.12212, "loss": 1.5536, "time": 0.90002}
{"mode": "train", "epoch": 7, "iter": 3950, "lr": 0.0002, "memory": 17588, "data_time": 0.01415, "decode.loss_ce": 1.43508, "decode.acc_seg": 34.2843, "loss": 1.43508, "time": 0.89999}
{"mode": "train", "epoch": 7, "iter": 4000, "lr": 0.0001, "memory": 17588, "data_time": 0.01409, "decode.loss_ce": 1.51736, "decode.acc_seg": 33.91747, "loss": 1.51736, "time": 0.94691}
{"mode": "val", "epoch": 7, "iter": 5104, "lr": 0.0001, "aAcc": 0.5768, "mIoU": 0.3242, "mAcc": 0.513, "mPrec": 0.4657, "IoU.aeroplane": 0.3938, "IoU.bag": 0.0019, "IoU.bed": 0.0832, "IoU.bedclothes": 0.097, "IoU.bench": 0.0, "IoU.bicycle": 0.558, "IoU.bird": 0.6519, "IoU.boat": 0.3545, "IoU.book": 0.0175, "IoU.bottle": 0.5863, "IoU.building": 0.1567, "IoU.bus": 0.772, "IoU.cabinet": 0.0932, "IoU.car": 0.6792, "IoU.cat": 0.8138, "IoU.ceiling": 0.3182, "IoU.chair": 0.2916, "IoU.cloth": 0.0592, "IoU.computer": 0.0568, "IoU.cow": 0.7112, "IoU.cup": 0.0365, "IoU.curtain": 0.2923, "IoU.dog": 0.7903, "IoU.door": 0.0997, "IoU.fence": 0.1884, "IoU.floor": 0.4827, "IoU.flower": 0.1685, "IoU.food": 0.073, "IoU.grass": 0.6217, "IoU.ground": 0.2436, "IoU.horse": 0.6222, "IoU.keyboard": 0.6351, "IoU.light": 0.1418, "IoU.motorbike": 0.6326, "IoU.mountain": 0.339, "IoU.mouse": 0.0, "IoU.person": 0.471, "IoU.plate": 0.0033, "IoU.platform": 0.0, "IoU.pottedplant": 0.3326, "IoU.road": 0.4141, "IoU.rock": 0.2958, "IoU.sheep": 0.7103, "IoU.shelves": 0.0525, "IoU.sidewalk": 0.123, "IoU.sign": 0.2499, "IoU.sky": 0.5711, "IoU.snow": 0.4922, "IoU.sofa": 0.3784, "IoU.table": 0.1587, "IoU.track": 0.0, "IoU.train": 0.4571, "IoU.tree": 0.4987, "IoU.truck": 0.1088, "IoU.tvmonitor": 0.4732, "IoU.wall": 0.3405, "IoU.water": 0.6652, "IoU.window": 0.1906, "IoU.wood": 0.0758, "Acc.aeroplane": 0.9656, "Acc.bag": 0.0019, "Acc.bed": 0.356, "Acc.bedclothes": 0.1077, "Acc.bench": 0.0, "Acc.bicycle": 0.9115, "Acc.bird": 0.9576, "Acc.boat": 0.8681, "Acc.book": 0.0175, "Acc.bottle": 0.7441, "Acc.building": 0.1612, "Acc.bus": 0.9181, "Acc.cabinet": 0.2499, "Acc.car": 0.8939, "Acc.cat": 0.9564, "Acc.ceiling": 0.7096, "Acc.chair": 0.3976, "Acc.cloth": 0.3256, "Acc.computer": 0.1757, "Acc.cow": 0.9066, "Acc.cup": 0.066, "Acc.curtain": 0.3682, "Acc.dog": 0.9164, "Acc.door": 0.5104, "Acc.fence": 0.2211, "Acc.floor": 0.6653, "Acc.flower": 0.3925, "Acc.food": 0.8454, "Acc.grass": 0.7309, "Acc.ground": 0.4215, "Acc.horse": 0.9493, "Acc.keyboard": 0.8816, "Acc.light": 0.5853, "Acc.motorbike": 0.8527, "Acc.mountain": 0.5214, "Acc.mouse": 0.0, "Acc.person": 0.5238, "Acc.plate": 0.0043, "Acc.platform": 0.0, "Acc.pottedplant": 0.7489, "Acc.road": 0.5984, "Acc.rock": 0.6152, "Acc.sheep": 0.8913, "Acc.shelves": 0.0581, "Acc.sidewalk": 0.6183, "Acc.sign": 0.4111, "Acc.sky": 0.5831, "Acc.snow": 0.6056, "Acc.sofa": 0.4814, "Acc.table": 0.4638, "Acc.track": 0.0, "Acc.train": 0.9118, "Acc.tree": 0.554, "Acc.truck": 0.2898, "Acc.tvmonitor": 0.5801, "Acc.wall": 0.4275, "Acc.water": 0.7295, "Acc.window": 0.2376, "Acc.wood": 0.3798, "Prec.aeroplane": 0.3994, "Prec.bag": 0.4458, "Prec.bed": 0.0979, "Prec.bedclothes": 0.4941, "Prec.bench": 0.0, "Prec.bicycle": 0.59, "Prec.bird": 0.6713, "Prec.boat": 0.3746, "Prec.book": 0.8999, "Prec.bottle": 0.7345, "Prec.building": 0.848, "Prec.bus": 0.8291, "Prec.cabinet": 0.1294, "Prec.car": 0.7387, "Prec.cat": 0.8451, "Prec.ceiling": 0.3658, "Prec.chair": 0.5225, "Prec.cloth": 0.0674, "Prec.computer": 0.0774, "Prec.cow": 0.7674, "Prec.cup": 0.0755, "Prec.curtain": 0.5863, "Prec.dog": 0.8518, "Prec.door": 0.1102, "Prec.fence": 0.5605, "Prec.floor": 0.6376, "Prec.flower": 0.2279, "Prec.food": 0.074, "Prec.grass": 0.8062, "Prec.ground": 0.366, "Prec.horse": 0.6436, "Prec.keyboard": 0.6943, "Prec.light": 0.1576, "Prec.motorbike": 0.7102, "Prec.mountain": 0.4921, "Prec.mouse": 0.0, "Prec.person": 0.8237, "Prec.plate": 0.0136, "Prec.platform": 0.0, "Prec.pottedplant": 0.3744, "Prec.road": 0.5735, "Prec.rock": 0.3629, "Prec.sheep": 0.7777, "Prec.shelves": 0.35, "Prec.sidewalk": 0.1331, "Prec.sign": 0.3893, "Prec.sky": 0.9654, "Prec.snow": 0.7243, "Prec.sofa": 0.6389, "Prec.table": 0.1944, "Prec.track": 0.0, "Prec.train": 0.4782, "Prec.tree": 0.8333, "Prec.truck": 0.1484, "Prec.tvmonitor": 0.7197, "Prec.wall": 0.626, "Prec.water": 0.883, "Prec.window": 0.4904, "Prec.wood": 0.0865}
