2023-02-20 00:49:00,878 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.2, V11.2.152
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.9.1+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.1+cu111
OpenCV: 4.7.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMSegmentation: 0.20.2+e20a1c2
------------------------------------------------------------

2023-02-20 00:49:00,878 - mmseg - INFO - Distributed training: False
2023-02-20 00:49:02,456 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained='open-mmlab://resnet101_v1c',
    backbone=dict(
        type='ResNetV1c',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 2, 4),
        strides=(1, 2, 1, 1),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True),
    decode_head=dict(
        type='MaskClipPlusHead',
        in_channels=2048,
        channels=1024,
        num_classes=0,
        dropout_ratio=0,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
        decode_module_cfg=dict(
            type='ASPPHeadV2', input_transform=None,
            dilations=(6, 12, 18, 24)),
        text_categories=59,
        text_channels=1024,
        text_embeddings_path='pretrain/context_RN50_clip_text.pth',
        cls_bg=False,
        norm_feat=False,
        clip_unlabeled_cats=[
            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
            19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
            36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,
            53, 54, 55, 56, 57, 58
        ],
        clip_cfg=dict(
            type='ResNetClip',
            depth=50,
            norm_cfg=dict(type='SyncBN', requires_grad=True),
            contract_dilation=True),
        clip_weights_path='pretrain/RN50_clip_weights.pth',
        reset_counter=True,
        start_clip_guided=(1, -1),
        start_self_train=(-1, -1)),
    feed_img_to_decode_head=True,
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'PascalContextDataset59'
data_root = 'data/VOCdevkit/VOC2010/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
img_scale = (520, 520)
crop_size = (480, 480)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='LoadAnnotations',
        reduce_zero_label=True,
        suppress_labels=[
            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
            19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
            36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,
            53, 54, 55, 56, 57, 58
        ]),
    dict(type='Resize', img_scale=(520, 520), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(480, 480), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(480, 480), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(520, 520),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=4,
    train=dict(
        type='PascalContextDataset59',
        data_root='data/VOCdevkit/VOC2010/',
        img_dir='JPEGImages',
        ann_dir='SegmentationClassContext',
        split='ImageSets/SegmentationContext/train.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='LoadAnnotations',
                reduce_zero_label=True,
                suppress_labels=[
                    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,
                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
                    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,
                    47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58
                ]),
            dict(type='Resize', img_scale=(520, 520), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(480, 480), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(480, 480), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='PascalContextDataset59',
        data_root='data/VOCdevkit/VOC2010/',
        img_dir='JPEGImages',
        ann_dir='SegmentationClassContext',
        split='ImageSets/SegmentationContext/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(520, 520),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='PascalContextDataset59',
        data_root='data/VOCdevkit/VOC2010/',
        img_dir='JPEGImages',
        ann_dir='SegmentationClassContext',
        split='ImageSets/SegmentationContext/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(520, 520),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.00025)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=4000)
checkpoint_config = dict(by_epoch=False, interval=2000)
evaluation = dict(interval=2000, metric='mIoU', pre_eval=True)
suppress_labels = [
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58
]
find_unused_parameters = True
work_dir = 'work_dirs/anno_free/r50-dl2'
gpu_ids = range(0, 1)
auto_resume = False

2023-02-20 00:49:02,457 - mmseg - INFO - Set random seed to 736543734, deterministic: False
2023-02-20 00:49:07,215 - mmseg - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet101_v1c'}
2023-02-20 00:49:07,806 - mmseg - INFO - initialize ResNetClip with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-20 00:49:08,111 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,112 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,113 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,114 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,116 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,117 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,118 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,200 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,202 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,203 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,204 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,206 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,207 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,211 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,212 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,214 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-20 00:49:08,305 - mmseg - INFO - Loaded text embeddings from pretrain/context_RN50_clip_text.pth
2023-02-20 00:49:08,558 - mmseg - INFO - Loaded clip weights from pretrain/RN50_clip_weights.pth
Name of parameter - Initialization information

backbone.stem.0.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.1.weight - torch.Size([32]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.1.bias - torch.Size([32]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.3.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.4.weight - torch.Size([32]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.4.bias - torch.Size([32]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.6.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.7.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.stem.7.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.6.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.7.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.8.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.9.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.10.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.11.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.12.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.13.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.14.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.15.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.16.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.17.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.18.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.19.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.20.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.21.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.bn1.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.bn1.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.bn2.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.bn2.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer3.22.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from open-mmlab://resnet101_v1c 

decode_head.decode_module.aspp_modules.0.conv.weight - torch.Size([1024, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.0.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.0.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.1.conv.weight - torch.Size([1024, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.1.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.1.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.2.conv.weight - torch.Size([1024, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.2.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.2.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.3.conv.weight - torch.Size([1024, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.3.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decode_module.aspp_modules.3.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.clip.stem.0.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.1.weight - torch.Size([32]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.1.bias - torch.Size([32]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.3.weight - torch.Size([32, 32, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.4.weight - torch.Size([32]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.4.bias - torch.Size([32]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.6.weight - torch.Size([64, 32, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.7.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.stem.7.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.downsample.1.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.downsample.2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.0.downsample.2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.1.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.bn1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.bn1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.bn2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer1.2.bn3.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.downsample.1.weight - torch.Size([512, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.downsample.2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.0.downsample.2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.1.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.2.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.bn1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.bn1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.bn2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer2.3.bn3.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.downsample.1.weight - torch.Size([1024, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.downsample.2.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.0.downsample.2.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.1.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.2.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.3.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.4.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.bn1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.bn1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.bn2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer3.5.bn3.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.downsample.1.weight - torch.Size([2048, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.downsample.2.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.0.downsample.2.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.1.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.bn1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.bn1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.bn2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.clip.layer4.2.bn3.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.q_proj.weight - torch.Size([2048, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.q_proj.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.k_proj.weight - torch.Size([2048, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.k_proj.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.v_proj.weight - torch.Size([2048, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.v_proj.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.c_proj.weight - torch.Size([1024, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  

decode_head.c_proj.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in MaskClipPlusHead  
2023-02-20 00:49:08,607 - mmseg - INFO - EncoderDecoder(
  (backbone): ResNetV1c(
    (stem): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
    )
    (stem_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (6): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (7): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (8): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (9): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (10): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (11): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (12): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (13): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (14): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (15): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (16): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (17): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (18): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (19): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (20): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (21): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (22): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet101_v1c'}
  (decode_head): MaskClipPlusHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (decode_module): ASPPHeadV2(
      input_transform=None, ignore_index=255, align_corners=False
      (aspp_modules): ASPPModuleV2(
        (0): ConvModule(
          (conv): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
          (bn): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
          (bn): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
          (bn): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)
          (bn): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (clip): ResNetClip(
      (stem): Sequential(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (7): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
      )
      (stem_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (layer1): ResLayer(
        (0): Bottleneck(
          (avgpool): Identity()
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): AvgPool2d(kernel_size=1, stride=1, padding=0)
            (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
      (layer2): ResLayer(
        (0): Bottleneck(
          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
      (layer3): ResLayer(
        (0): Bottleneck(
          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
      (layer4): ResLayer(
        (0): Bottleneck(
          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
    )
    init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
    (q_proj): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
    (k_proj): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
    (v_proj): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))
    (c_proj): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
  )
)
2023-02-20 00:49:08,702 - mmseg - INFO - Loaded 4996 images
2023-02-20 00:49:10,761 - mmseg - INFO - Loaded 5104 images
2023-02-20 00:49:10,761 - mmseg - INFO - Start running, host: root@workspace-p4cxarvku5qr-0, work_dir: /root/sj/MaskCLIP_SegFormer/work_dirs/anno_free/r50-dl2
2023-02-20 00:49:10,761 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-20 00:49:10,762 - mmseg - INFO - workflow: [('train', 1)], max: 4000 iters
2023-02-20 00:49:10,762 - mmseg - INFO - Checkpoints will be saved to /root/sj/MaskCLIP_SegFormer/work_dirs/anno_free/r50-dl2 by HardDiskBackend.
2023-02-20 00:49:13,903 - mmseg - INFO - Start clip guided training
2023-02-20 00:50:03,693 - mmseg - INFO - Iter [50/4000]	lr: 4.946e-03, eta: 1:08:50, time: 1.046, data_time: 0.021, memory: 18986, decode.loss_ce: 2.9779, decode.acc_seg: 2.2313, loss: 2.9779
2023-02-20 00:50:51,198 - mmseg - INFO - Iter [100/4000]	lr: 4.891e-03, eta: 1:04:51, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 2.5826, decode.acc_seg: 6.8155, loss: 2.5826
2023-02-20 00:51:38,747 - mmseg - INFO - Iter [150/4000]	lr: 4.835e-03, eta: 1:03:01, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 2.2957, decode.acc_seg: 14.9293, loss: 2.2957
2023-02-20 00:52:26,312 - mmseg - INFO - Iter [200/4000]	lr: 4.780e-03, eta: 1:01:43, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 2.1256, decode.acc_seg: 19.0365, loss: 2.1256
2023-02-20 00:53:13,880 - mmseg - INFO - Iter [250/4000]	lr: 4.725e-03, eta: 1:00:36, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 2.0118, decode.acc_seg: 21.5743, loss: 2.0118
2023-02-20 00:54:01,421 - mmseg - INFO - Iter [300/4000]	lr: 4.669e-03, eta: 0:59:36, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.8801, decode.acc_seg: 24.5678, loss: 1.8801
2023-02-20 00:54:48,951 - mmseg - INFO - Iter [350/4000]	lr: 4.613e-03, eta: 0:58:40, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.8414, decode.acc_seg: 24.2628, loss: 1.8414
2023-02-20 00:55:36,488 - mmseg - INFO - Iter [400/4000]	lr: 4.558e-03, eta: 0:57:45, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.8390, decode.acc_seg: 25.7486, loss: 1.8390
2023-02-20 00:56:24,001 - mmseg - INFO - Iter [450/4000]	lr: 4.502e-03, eta: 0:56:52, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.7623, decode.acc_seg: 27.9402, loss: 1.7623
2023-02-20 00:57:11,518 - mmseg - INFO - Iter [500/4000]	lr: 4.446e-03, eta: 0:56:00, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.7446, decode.acc_seg: 25.9032, loss: 1.7446
2023-02-20 00:57:59,026 - mmseg - INFO - Iter [550/4000]	lr: 4.390e-03, eta: 0:55:09, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.7478, decode.acc_seg: 26.4596, loss: 1.7478
2023-02-20 00:58:46,514 - mmseg - INFO - Iter [600/4000]	lr: 4.334e-03, eta: 0:54:18, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.7799, decode.acc_seg: 28.3106, loss: 1.7799
2023-02-20 00:59:36,293 - mmseg - INFO - Iter [650/4000]	lr: 4.278e-03, eta: 0:53:40, time: 0.996, data_time: 0.058, memory: 18986, decode.loss_ce: 1.6770, decode.acc_seg: 29.4996, loss: 1.6770
2023-02-20 01:00:23,707 - mmseg - INFO - Iter [700/4000]	lr: 4.222e-03, eta: 0:52:49, time: 0.948, data_time: 0.010, memory: 18986, decode.loss_ce: 1.6156, decode.acc_seg: 29.3327, loss: 1.6156
2023-02-20 01:01:11,154 - mmseg - INFO - Iter [750/4000]	lr: 4.166e-03, eta: 0:51:58, time: 0.949, data_time: 0.010, memory: 18986, decode.loss_ce: 1.6143, decode.acc_seg: 29.5070, loss: 1.6143
2023-02-20 01:01:58,588 - mmseg - INFO - Iter [800/4000]	lr: 4.110e-03, eta: 0:51:08, time: 0.949, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5818, decode.acc_seg: 29.8088, loss: 1.5818
2023-02-20 01:02:46,079 - mmseg - INFO - Iter [850/4000]	lr: 4.053e-03, eta: 0:50:19, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.7111, decode.acc_seg: 30.1634, loss: 1.7111
2023-02-20 01:03:33,581 - mmseg - INFO - Iter [900/4000]	lr: 3.997e-03, eta: 0:49:29, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5766, decode.acc_seg: 29.1020, loss: 1.5766
2023-02-20 01:04:21,074 - mmseg - INFO - Iter [950/4000]	lr: 3.940e-03, eta: 0:48:40, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5876, decode.acc_seg: 28.9593, loss: 1.5876
2023-02-20 01:05:08,622 - mmseg - INFO - Exp name: maskclip_plus_r50_deeplabv2_r101-d8_480x480_4k_pascal_context_59.py
2023-02-20 01:05:08,623 - mmseg - INFO - Iter [1000/4000]	lr: 3.883e-03, eta: 0:47:51, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5411, decode.acc_seg: 31.7994, loss: 1.5411
2023-02-20 01:05:56,164 - mmseg - INFO - Iter [1050/4000]	lr: 3.827e-03, eta: 0:47:02, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5613, decode.acc_seg: 29.8320, loss: 1.5613
2023-02-20 01:06:43,724 - mmseg - INFO - Iter [1100/4000]	lr: 3.770e-03, eta: 0:46:14, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5132, decode.acc_seg: 30.0537, loss: 1.5132
2023-02-20 01:07:31,247 - mmseg - INFO - Iter [1150/4000]	lr: 3.713e-03, eta: 0:45:25, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5380, decode.acc_seg: 30.8571, loss: 1.5380
2023-02-20 01:08:18,771 - mmseg - INFO - Iter [1200/4000]	lr: 3.656e-03, eta: 0:44:37, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5597, decode.acc_seg: 31.9109, loss: 1.5597
2023-02-20 01:09:08,662 - mmseg - INFO - Iter [1250/4000]	lr: 3.599e-03, eta: 0:43:53, time: 0.998, data_time: 0.058, memory: 18986, decode.loss_ce: 1.6039, decode.acc_seg: 31.8393, loss: 1.6039
2023-02-20 01:09:56,109 - mmseg - INFO - Iter [1300/4000]	lr: 3.541e-03, eta: 0:43:05, time: 0.949, data_time: 0.010, memory: 18986, decode.loss_ce: 1.5449, decode.acc_seg: 32.9243, loss: 1.5449
2023-02-20 01:10:43,588 - mmseg - INFO - Iter [1350/4000]	lr: 3.484e-03, eta: 0:42:16, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5434, decode.acc_seg: 32.7758, loss: 1.5434
2023-02-20 01:11:31,080 - mmseg - INFO - Iter [1400/4000]	lr: 3.426e-03, eta: 0:41:27, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5151, decode.acc_seg: 31.6726, loss: 1.5151
2023-02-20 01:12:18,569 - mmseg - INFO - Iter [1450/4000]	lr: 3.369e-03, eta: 0:40:39, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4679, decode.acc_seg: 32.1569, loss: 1.4679
2023-02-20 01:13:06,060 - mmseg - INFO - Iter [1500/4000]	lr: 3.311e-03, eta: 0:39:51, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.6012, decode.acc_seg: 31.9934, loss: 1.6012
2023-02-20 01:13:53,555 - mmseg - INFO - Iter [1550/4000]	lr: 3.253e-03, eta: 0:39:02, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5754, decode.acc_seg: 31.4772, loss: 1.5754
2023-02-20 01:14:41,039 - mmseg - INFO - Iter [1600/4000]	lr: 3.195e-03, eta: 0:38:14, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.5424, decode.acc_seg: 31.0832, loss: 1.5424
2023-02-20 01:15:28,533 - mmseg - INFO - Iter [1650/4000]	lr: 3.137e-03, eta: 0:37:26, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4866, decode.acc_seg: 30.9571, loss: 1.4866
2023-02-20 01:16:15,999 - mmseg - INFO - Iter [1700/4000]	lr: 3.079e-03, eta: 0:36:37, time: 0.949, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4717, decode.acc_seg: 31.3109, loss: 1.4717
2023-02-20 01:17:03,497 - mmseg - INFO - Iter [1750/4000]	lr: 3.021e-03, eta: 0:35:49, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4744, decode.acc_seg: 32.1933, loss: 1.4744
2023-02-20 01:17:51,015 - mmseg - INFO - Iter [1800/4000]	lr: 2.962e-03, eta: 0:35:01, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4305, decode.acc_seg: 32.7975, loss: 1.4305
2023-02-20 01:18:38,548 - mmseg - INFO - Iter [1850/4000]	lr: 2.904e-03, eta: 0:34:13, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4847, decode.acc_seg: 32.4445, loss: 1.4847
2023-02-20 01:19:28,394 - mmseg - INFO - Iter [1900/4000]	lr: 2.845e-03, eta: 0:33:28, time: 0.997, data_time: 0.058, memory: 18986, decode.loss_ce: 1.4294, decode.acc_seg: 32.2528, loss: 1.4294
2023-02-20 01:20:15,886 - mmseg - INFO - Iter [1950/4000]	lr: 2.786e-03, eta: 0:32:40, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.4024, decode.acc_seg: 32.4731, loss: 1.4024
2023-02-20 01:21:03,393 - mmseg - INFO - Saving checkpoint at 2000 iterations
2023-02-20 01:21:05,376 - mmseg - INFO - Exp name: maskclip_plus_r50_deeplabv2_r101-d8_480x480_4k_pascal_context_59.py
2023-02-20 01:21:05,376 - mmseg - INFO - Iter [2000/4000]	lr: 2.727e-03, eta: 0:31:53, time: 0.990, data_time: 0.010, memory: 18986, decode.loss_ce: 1.4578, decode.acc_seg: 34.0641, loss: 1.4578
2023-02-20 01:39:30,054 - mmseg - INFO - per class results:
2023-02-20 01:39:30,057 - mmseg - INFO - 
+-------------+-------+-------+-------+
|    Class    |  IoU  |  Acc  |  Prec |
+-------------+-------+-------+-------+
|  aeroplane  | 41.23 |  89.7 | 43.28 |
|     bag     |  0.39 |  0.4  | 18.93 |
|     bed     |  4.02 | 15.38 |  5.17 |
|  bedclothes |  9.97 | 28.49 | 13.29 |
|    bench    |  3.29 | 24.67 |  3.66 |
|   bicycle   |  44.7 | 90.22 | 46.98 |
|     bird    | 45.66 | 84.22 | 49.94 |
|     boat    | 23.68 | 71.62 | 26.14 |
|     book    |  0.0  |  0.0  |  nan  |
|    bottle   | 52.79 | 75.12 | 63.98 |
|   building  | 15.41 | 15.87 | 84.29 |
|     bus     | 69.17 | 80.71 | 82.87 |
|   cabinet   | 16.88 | 22.43 | 40.56 |
|     car     | 64.77 |  83.1 |  74.6 |
|     cat     | 68.19 |  80.8 | 81.38 |
|   ceiling   | 30.59 | 57.06 | 39.73 |
|    chair    | 23.78 | 29.63 | 54.65 |
|    cloth    |  2.06 |  4.4  |  3.72 |
|   computer  |  2.38 | 84.61 |  2.39 |
|     cow     | 35.13 | 50.54 | 53.53 |
|     cup     |  8.03 |  8.85 | 46.42 |
|   curtain   | 18.07 | 46.94 | 22.71 |
|     dog     | 58.82 | 69.92 | 78.74 |
|     door    |  8.24 | 53.58 |  8.88 |
|    fence    | 13.55 | 61.76 | 14.79 |
|    floor    | 34.33 | 52.33 | 49.94 |
|    flower   | 15.03 |  19.6 | 39.19 |
|     food    | 16.08 | 65.68 | 17.55 |
|    grass    | 42.39 | 46.44 | 82.94 |
|    ground   |  5.04 |  5.27 | 53.56 |
|    horse    | 29.55 | 87.85 | 30.81 |
|   keyboard  | 52.91 | 54.28 | 95.44 |
|    light    |  0.73 |  0.77 | 12.74 |
|  motorbike  |  50.7 |  78.1 |  59.1 |
|   mountain  | 17.27 | 42.88 | 22.42 |
|    mouse    |  0.0  |  0.96 |  0.0  |
|    person   |  33.9 | 37.68 | 77.13 |
|    plate    |  0.0  |  0.0  |  0.0  |
|   platform  |  7.81 | 26.96 |  9.91 |
| pottedplant | 33.62 | 79.38 | 36.83 |
|     road    | 31.38 | 40.92 | 57.37 |
|     rock    | 17.79 | 40.26 | 24.18 |
|    sheep    |  7.8  | 78.66 |  7.97 |
|   shelves   |  7.72 | 34.31 |  9.06 |
|   sidewalk  |  9.65 | 49.22 | 10.72 |
|     sign    | 22.63 | 37.63 | 36.22 |
|     sky     | 63.62 | 66.23 | 94.17 |
|     snow    | 27.85 | 62.56 | 33.42 |
|     sofa    | 28.22 | 68.93 | 32.33 |
|    table    | 26.73 | 48.82 | 37.14 |
|    track    |  0.0  |  0.0  |  0.0  |
|    train    | 48.08 | 84.28 | 52.81 |
|     tree    | 38.38 | 40.63 | 87.41 |
|    truck    |  6.52 | 12.87 | 11.65 |
|  tvmonitor  | 27.79 | 32.36 | 66.32 |
|     wall    | 12.34 | 13.18 | 65.75 |
|    water    | 28.88 | 34.01 | 65.68 |
|    window   | 13.74 | 24.16 | 24.15 |
|     wood    | 12.26 | 30.56 |  17.0 |
+-------------+-------+-------+-------+
2023-02-20 01:39:30,057 - mmseg - INFO - Summary:
2023-02-20 01:39:30,057 - mmseg - INFO - 
+-------+-------+-------+-------+
|  aAcc |  mIoU |  mAcc | mPrec |
+-------+-------+-------+-------+
| 45.04 | 24.26 | 44.54 | 39.34 |
+-------+-------+-------+-------+
2023-02-20 01:39:30,071 - mmseg - INFO - Exp name: maskclip_plus_r50_deeplabv2_r101-d8_480x480_4k_pascal_context_59.py
2023-02-20 01:39:30,072 - mmseg - INFO - Iter(val) [5104]	aAcc: 0.4504, mIoU: 0.2426, mAcc: 0.4454, mPrec: 0.3934, IoU.aeroplane: 0.4123, IoU.bag: 0.0039, IoU.bed: 0.0402, IoU.bedclothes: 0.0997, IoU.bench: 0.0329, IoU.bicycle: 0.4470, IoU.bird: 0.4566, IoU.boat: 0.2368, IoU.book: 0.0000, IoU.bottle: 0.5279, IoU.building: 0.1541, IoU.bus: 0.6917, IoU.cabinet: 0.1688, IoU.car: 0.6477, IoU.cat: 0.6819, IoU.ceiling: 0.3059, IoU.chair: 0.2378, IoU.cloth: 0.0206, IoU.computer: 0.0238, IoU.cow: 0.3513, IoU.cup: 0.0803, IoU.curtain: 0.1807, IoU.dog: 0.5882, IoU.door: 0.0824, IoU.fence: 0.1355, IoU.floor: 0.3433, IoU.flower: 0.1503, IoU.food: 0.1608, IoU.grass: 0.4239, IoU.ground: 0.0504, IoU.horse: 0.2955, IoU.keyboard: 0.5291, IoU.light: 0.0073, IoU.motorbike: 0.5070, IoU.mountain: 0.1727, IoU.mouse: 0.0000, IoU.person: 0.3390, IoU.plate: 0.0000, IoU.platform: 0.0781, IoU.pottedplant: 0.3362, IoU.road: 0.3138, IoU.rock: 0.1779, IoU.sheep: 0.0780, IoU.shelves: 0.0772, IoU.sidewalk: 0.0965, IoU.sign: 0.2263, IoU.sky: 0.6362, IoU.snow: 0.2785, IoU.sofa: 0.2822, IoU.table: 0.2673, IoU.track: 0.0000, IoU.train: 0.4808, IoU.tree: 0.3838, IoU.truck: 0.0652, IoU.tvmonitor: 0.2779, IoU.wall: 0.1234, IoU.water: 0.2888, IoU.window: 0.1374, IoU.wood: 0.1226, Acc.aeroplane: 0.8970, Acc.bag: 0.0040, Acc.bed: 0.1538, Acc.bedclothes: 0.2849, Acc.bench: 0.2467, Acc.bicycle: 0.9022, Acc.bird: 0.8422, Acc.boat: 0.7162, Acc.book: 0.0000, Acc.bottle: 0.7512, Acc.building: 0.1587, Acc.bus: 0.8071, Acc.cabinet: 0.2243, Acc.car: 0.8310, Acc.cat: 0.8080, Acc.ceiling: 0.5706, Acc.chair: 0.2963, Acc.cloth: 0.0440, Acc.computer: 0.8461, Acc.cow: 0.5054, Acc.cup: 0.0885, Acc.curtain: 0.4694, Acc.dog: 0.6992, Acc.door: 0.5358, Acc.fence: 0.6176, Acc.floor: 0.5233, Acc.flower: 0.1960, Acc.food: 0.6568, Acc.grass: 0.4644, Acc.ground: 0.0527, Acc.horse: 0.8785, Acc.keyboard: 0.5428, Acc.light: 0.0077, Acc.motorbike: 0.7810, Acc.mountain: 0.4288, Acc.mouse: 0.0096, Acc.person: 0.3768, Acc.plate: 0.0000, Acc.platform: 0.2696, Acc.pottedplant: 0.7938, Acc.road: 0.4092, Acc.rock: 0.4026, Acc.sheep: 0.7866, Acc.shelves: 0.3431, Acc.sidewalk: 0.4922, Acc.sign: 0.3763, Acc.sky: 0.6623, Acc.snow: 0.6256, Acc.sofa: 0.6893, Acc.table: 0.4882, Acc.track: 0.0000, Acc.train: 0.8428, Acc.tree: 0.4063, Acc.truck: 0.1287, Acc.tvmonitor: 0.3236, Acc.wall: 0.1318, Acc.water: 0.3401, Acc.window: 0.2416, Acc.wood: 0.3056, Prec.aeroplane: 0.4328, Prec.bag: 0.1893, Prec.bed: 0.0517, Prec.bedclothes: 0.1329, Prec.bench: 0.0366, Prec.bicycle: 0.4698, Prec.bird: 0.4994, Prec.boat: 0.2614, Prec.book: nan, Prec.bottle: 0.6398, Prec.building: 0.8429, Prec.bus: 0.8287, Prec.cabinet: 0.4056, Prec.car: 0.7460, Prec.cat: 0.8138, Prec.ceiling: 0.3973, Prec.chair: 0.5465, Prec.cloth: 0.0372, Prec.computer: 0.0239, Prec.cow: 0.5353, Prec.cup: 0.4642, Prec.curtain: 0.2271, Prec.dog: 0.7874, Prec.door: 0.0888, Prec.fence: 0.1479, Prec.floor: 0.4994, Prec.flower: 0.3919, Prec.food: 0.1755, Prec.grass: 0.8294, Prec.ground: 0.5356, Prec.horse: 0.3081, Prec.keyboard: 0.9544, Prec.light: 0.1274, Prec.motorbike: 0.5910, Prec.mountain: 0.2242, Prec.mouse: 0.0000, Prec.person: 0.7713, Prec.plate: 0.0000, Prec.platform: 0.0991, Prec.pottedplant: 0.3683, Prec.road: 0.5737, Prec.rock: 0.2418, Prec.sheep: 0.0797, Prec.shelves: 0.0906, Prec.sidewalk: 0.1072, Prec.sign: 0.3622, Prec.sky: 0.9417, Prec.snow: 0.3342, Prec.sofa: 0.3233, Prec.table: 0.3714, Prec.track: 0.0000, Prec.train: 0.5281, Prec.tree: 0.8741, Prec.truck: 0.1165, Prec.tvmonitor: 0.6632, Prec.wall: 0.6575, Prec.water: 0.6568, Prec.window: 0.2415, Prec.wood: 0.1700
2023-02-20 01:40:17,342 - mmseg - INFO - Iter [2050/4000]	lr: 2.668e-03, eta: 0:48:36, time: 23.039, data_time: 22.103, memory: 18986, decode.loss_ce: 1.4158, decode.acc_seg: 31.7513, loss: 1.4158
2023-02-20 01:41:04,829 - mmseg - INFO - Iter [2100/4000]	lr: 2.609e-03, eta: 0:46:56, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3638, decode.acc_seg: 32.3710, loss: 1.3638
2023-02-20 01:41:52,337 - mmseg - INFO - Iter [2150/4000]	lr: 2.549e-03, eta: 0:45:19, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.4396, decode.acc_seg: 33.7927, loss: 1.4396
2023-02-20 01:42:39,851 - mmseg - INFO - Iter [2200/4000]	lr: 2.489e-03, eta: 0:43:45, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3603, decode.acc_seg: 33.3807, loss: 1.3603
2023-02-20 01:43:27,380 - mmseg - INFO - Iter [2250/4000]	lr: 2.430e-03, eta: 0:42:12, time: 0.951, data_time: 0.010, memory: 18986, decode.loss_ce: 1.4449, decode.acc_seg: 33.2580, loss: 1.4449
2023-02-20 01:44:14,870 - mmseg - INFO - Iter [2300/4000]	lr: 2.370e-03, eta: 0:40:41, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.4026, decode.acc_seg: 33.0020, loss: 1.4026
2023-02-20 01:45:02,368 - mmseg - INFO - Iter [2350/4000]	lr: 2.310e-03, eta: 0:39:12, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3825, decode.acc_seg: 33.2258, loss: 1.3825
2023-02-20 01:45:49,889 - mmseg - INFO - Iter [2400/4000]	lr: 2.249e-03, eta: 0:37:45, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3830, decode.acc_seg: 32.8035, loss: 1.3830
2023-02-20 01:46:37,399 - mmseg - INFO - Iter [2450/4000]	lr: 2.189e-03, eta: 0:36:20, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4149, decode.acc_seg: 34.3106, loss: 1.4149
2023-02-20 01:47:27,251 - mmseg - INFO - Iter [2500/4000]	lr: 2.128e-03, eta: 0:34:57, time: 0.997, data_time: 0.058, memory: 18986, decode.loss_ce: 1.3886, decode.acc_seg: 33.4466, loss: 1.3886
2023-02-20 01:48:14,658 - mmseg - INFO - Iter [2550/4000]	lr: 2.067e-03, eta: 0:33:34, time: 0.948, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3395, decode.acc_seg: 34.2974, loss: 1.3395
2023-02-20 01:49:02,129 - mmseg - INFO - Iter [2600/4000]	lr: 2.006e-03, eta: 0:32:13, time: 0.949, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3228, decode.acc_seg: 33.2394, loss: 1.3228
2023-02-20 01:49:49,638 - mmseg - INFO - Iter [2650/4000]	lr: 1.945e-03, eta: 0:30:53, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3715, decode.acc_seg: 34.5229, loss: 1.3715
2023-02-20 01:50:37,124 - mmseg - INFO - Iter [2700/4000]	lr: 1.883e-03, eta: 0:29:34, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3928, decode.acc_seg: 34.3548, loss: 1.3928
2023-02-20 01:51:24,636 - mmseg - INFO - Iter [2750/4000]	lr: 1.821e-03, eta: 0:28:16, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3061, decode.acc_seg: 33.8077, loss: 1.3061
2023-02-20 01:52:12,136 - mmseg - INFO - Iter [2800/4000]	lr: 1.759e-03, eta: 0:27:00, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3503, decode.acc_seg: 34.4954, loss: 1.3503
2023-02-20 01:52:59,648 - mmseg - INFO - Iter [2850/4000]	lr: 1.697e-03, eta: 0:25:44, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.4119, decode.acc_seg: 35.1232, loss: 1.4119
2023-02-20 01:53:47,148 - mmseg - INFO - Iter [2900/4000]	lr: 1.634e-03, eta: 0:24:30, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3723, decode.acc_seg: 33.9728, loss: 1.3723
2023-02-20 01:54:34,653 - mmseg - INFO - Iter [2950/4000]	lr: 1.572e-03, eta: 0:23:16, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3725, decode.acc_seg: 34.3994, loss: 1.3725
2023-02-20 01:55:22,149 - mmseg - INFO - Exp name: maskclip_plus_r50_deeplabv2_r101-d8_480x480_4k_pascal_context_59.py
2023-02-20 01:55:22,149 - mmseg - INFO - Iter [3000/4000]	lr: 1.508e-03, eta: 0:22:03, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3843, decode.acc_seg: 34.6059, loss: 1.3843
2023-02-20 01:56:09,643 - mmseg - INFO - Iter [3050/4000]	lr: 1.445e-03, eta: 0:20:51, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3648, decode.acc_seg: 34.0103, loss: 1.3648
2023-02-20 01:56:57,154 - mmseg - INFO - Iter [3100/4000]	lr: 1.381e-03, eta: 0:19:40, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3659, decode.acc_seg: 33.4906, loss: 1.3659
2023-02-20 01:57:46,856 - mmseg - INFO - Iter [3150/4000]	lr: 1.317e-03, eta: 0:18:30, time: 0.994, data_time: 0.056, memory: 18986, decode.loss_ce: 1.3303, decode.acc_seg: 33.8664, loss: 1.3303
2023-02-20 01:58:34,291 - mmseg - INFO - Iter [3200/4000]	lr: 1.252e-03, eta: 0:17:20, time: 0.949, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3958, decode.acc_seg: 35.2390, loss: 1.3958
2023-02-20 01:59:21,743 - mmseg - INFO - Iter [3250/4000]	lr: 1.187e-03, eta: 0:16:11, time: 0.949, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3538, decode.acc_seg: 34.1063, loss: 1.3538
2023-02-20 02:00:09,219 - mmseg - INFO - Iter [3300/4000]	lr: 1.122e-03, eta: 0:15:03, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3399, decode.acc_seg: 34.4136, loss: 1.3399
2023-02-20 02:00:56,688 - mmseg - INFO - Iter [3350/4000]	lr: 1.056e-03, eta: 0:13:55, time: 0.949, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3059, decode.acc_seg: 34.0736, loss: 1.3059
2023-02-20 02:01:44,194 - mmseg - INFO - Iter [3400/4000]	lr: 9.899e-04, eta: 0:12:48, time: 0.950, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3952, decode.acc_seg: 35.3826, loss: 1.3952
2023-02-20 02:02:31,733 - mmseg - INFO - Iter [3450/4000]	lr: 9.230e-04, eta: 0:11:41, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3022, decode.acc_seg: 34.2894, loss: 1.3022
2023-02-20 02:03:19,267 - mmseg - INFO - Iter [3500/4000]	lr: 8.554e-04, eta: 0:10:35, time: 0.951, data_time: 0.011, memory: 18986, decode.loss_ce: 1.2913, decode.acc_seg: 35.3883, loss: 1.2913
2023-02-20 02:04:06,845 - mmseg - INFO - Iter [3550/4000]	lr: 7.872e-04, eta: 0:09:29, time: 0.952, data_time: 0.011, memory: 18986, decode.loss_ce: 1.2942, decode.acc_seg: 34.5610, loss: 1.2942
2023-02-20 02:04:54,430 - mmseg - INFO - Iter [3600/4000]	lr: 7.183e-04, eta: 0:08:24, time: 0.952, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3278, decode.acc_seg: 33.8927, loss: 1.3278
2023-02-20 02:05:42,007 - mmseg - INFO - Iter [3650/4000]	lr: 6.484e-04, eta: 0:07:20, time: 0.952, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3127, decode.acc_seg: 35.3064, loss: 1.3127
2023-02-20 02:06:29,588 - mmseg - INFO - Iter [3700/4000]	lr: 5.776e-04, eta: 0:06:16, time: 0.952, data_time: 0.011, memory: 18986, decode.loss_ce: 1.3464, decode.acc_seg: 34.5760, loss: 1.3464
2023-02-20 02:07:19,546 - mmseg - INFO - Iter [3750/4000]	lr: 5.056e-04, eta: 0:05:12, time: 0.999, data_time: 0.059, memory: 18986, decode.loss_ce: 1.3696, decode.acc_seg: 35.2546, loss: 1.3696
2023-02-20 02:08:06,971 - mmseg - INFO - Iter [3800/4000]	lr: 4.321e-04, eta: 0:04:09, time: 0.948, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3368, decode.acc_seg: 35.7161, loss: 1.3368
2023-02-20 02:08:54,432 - mmseg - INFO - Iter [3850/4000]	lr: 3.567e-04, eta: 0:03:06, time: 0.949, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3460, decode.acc_seg: 36.3018, loss: 1.3460
2023-02-20 02:09:41,914 - mmseg - INFO - Iter [3900/4000]	lr: 2.787e-04, eta: 0:02:03, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3141, decode.acc_seg: 33.7085, loss: 1.3141
2023-02-20 02:10:29,405 - mmseg - INFO - Iter [3950/4000]	lr: 1.966e-04, eta: 0:01:01, time: 0.950, data_time: 0.010, memory: 18986, decode.loss_ce: 1.2887, decode.acc_seg: 34.8955, loss: 1.2887
2023-02-20 02:11:16,884 - mmseg - INFO - Saving checkpoint at 4000 iterations
2023-02-20 02:11:18,837 - mmseg - INFO - Exp name: maskclip_plus_r50_deeplabv2_r101-d8_480x480_4k_pascal_context_59.py
2023-02-20 02:11:18,837 - mmseg - INFO - Iter [4000/4000]	lr: 1.028e-04, eta: 0:00:00, time: 0.989, data_time: 0.010, memory: 18986, decode.loss_ce: 1.3159, decode.acc_seg: 35.0281, loss: 1.3159
2023-02-20 02:26:27,422 - mmseg - INFO - per class results:
2023-02-20 02:26:27,425 - mmseg - INFO - 
+-------------+-------+-------+-------+
|    Class    |  IoU  |  Acc  |  Prec |
+-------------+-------+-------+-------+
|  aeroplane  | 40.35 | 88.21 | 42.65 |
|     bag     |  2.25 |  2.47 | 19.98 |
|     bed     |  4.12 | 17.24 |  5.14 |
|  bedclothes | 11.62 | 31.97 | 15.44 |
|    bench    |  3.95 | 21.74 |  4.6  |
|   bicycle   | 47.39 | 87.92 | 50.69 |
|     bird    | 46.43 | 80.45 | 52.33 |
|     boat    | 22.83 | 67.23 | 25.69 |
|     book    |  0.0  |  0.0  |  nan  |
|    bottle   |  52.4 | 73.77 |  64.4 |
|   building  | 16.52 | 17.12 |  82.3 |
|     bus     | 68.91 | 85.05 | 78.42 |
|   cabinet   | 17.41 | 23.75 | 39.48 |
|     car     |  61.7 | 82.53 | 70.96 |
|     cat     | 66.25 | 75.92 | 83.88 |
|   ceiling   | 30.97 | 56.47 | 40.68 |
|    chair    |  23.8 | 29.06 | 56.84 |
|    cloth    |  2.52 |  5.66 |  4.35 |
|   computer  |  2.11 |  84.4 |  2.11 |
|     cow     | 34.28 | 50.89 | 51.23 |
|     cup     |  21.6 | 30.13 | 43.28 |
|   curtain   | 16.83 | 48.64 | 20.47 |
|     dog     | 57.31 | 68.72 | 77.54 |
|     door    |  7.62 |  57.3 |  8.08 |
|    fence    | 13.58 | 59.98 | 14.93 |
|    floor    | 34.71 | 47.52 |  56.3 |
|    flower   | 22.61 | 38.73 |  35.2 |
|     food    |  15.5 | 65.32 | 16.89 |
|    grass    | 45.38 |  49.8 | 83.65 |
|    ground   |  6.6  |  6.93 | 58.07 |
|    horse    | 25.93 | 90.36 | 26.66 |
|   keyboard  | 57.36 | 60.12 |  92.6 |
|    light    |  5.66 |  8.7  | 13.92 |
|  motorbike  | 52.55 | 78.19 | 61.57 |
|   mountain  | 19.82 | 44.51 | 26.33 |
|    mouse    |  0.01 |  2.77 |  0.01 |
|    person   | 33.21 | 38.87 |  69.5 |
|    plate    |  0.09 |  0.1  |  0.88 |
|   platform  |  7.55 | 27.23 |  9.46 |
| pottedplant |  32.3 | 76.15 | 35.93 |
|     road    | 28.95 |  35.8 | 60.19 |
|     rock    | 19.16 | 45.73 |  24.8 |
|    sheep    |  9.21 | 78.23 |  9.46 |
|   shelves   |  9.47 | 35.99 | 11.39 |
|   sidewalk  |  9.89 | 54.69 | 10.77 |
|     sign    | 23.24 | 46.19 | 31.88 |
|     sky     | 62.28 | 65.42 | 92.84 |
|     snow    | 27.39 |  68.4 | 31.35 |
|     sofa    | 29.51 | 68.29 |  34.2 |
|    table    | 25.72 | 40.45 | 41.39 |
|    track    |  0.0  |  0.0  |  0.0  |
|    train    | 49.04 | 83.47 | 54.31 |
|     tree    | 34.75 | 36.25 | 89.41 |
|    truck    |  6.57 |  19.1 |  9.1  |
|  tvmonitor  | 27.61 | 31.94 | 67.03 |
|     wall    | 14.37 | 15.68 | 63.31 |
|    water    | 29.75 | 32.96 | 75.36 |
|    window   | 14.19 | 31.63 | 20.47 |
|     wood    | 11.12 | 26.83 | 15.96 |
+-------------+-------+-------+-------+
2023-02-20 02:26:27,426 - mmseg - INFO - Summary:
2023-02-20 02:26:27,426 - mmseg - INFO - 
+-------+-------+-------+-------+
|  aAcc |  mIoU |  mAcc | mPrec |
+-------+-------+-------+-------+
| 44.94 | 24.82 | 45.74 | 39.41 |
+-------+-------+-------+-------+
2023-02-20 02:26:27,445 - mmseg - INFO - Exp name: maskclip_plus_r50_deeplabv2_r101-d8_480x480_4k_pascal_context_59.py
2023-02-20 02:26:27,446 - mmseg - INFO - Iter(val) [5104]	aAcc: 0.4494, mIoU: 0.2482, mAcc: 0.4574, mPrec: 0.3941, IoU.aeroplane: 0.4035, IoU.bag: 0.0225, IoU.bed: 0.0412, IoU.bedclothes: 0.1162, IoU.bench: 0.0395, IoU.bicycle: 0.4739, IoU.bird: 0.4643, IoU.boat: 0.2283, IoU.book: 0.0000, IoU.bottle: 0.5240, IoU.building: 0.1652, IoU.bus: 0.6891, IoU.cabinet: 0.1741, IoU.car: 0.6170, IoU.cat: 0.6625, IoU.ceiling: 0.3097, IoU.chair: 0.2380, IoU.cloth: 0.0252, IoU.computer: 0.0211, IoU.cow: 0.3428, IoU.cup: 0.2160, IoU.curtain: 0.1683, IoU.dog: 0.5731, IoU.door: 0.0762, IoU.fence: 0.1358, IoU.floor: 0.3471, IoU.flower: 0.2261, IoU.food: 0.1550, IoU.grass: 0.4538, IoU.ground: 0.0660, IoU.horse: 0.2593, IoU.keyboard: 0.5736, IoU.light: 0.0566, IoU.motorbike: 0.5255, IoU.mountain: 0.1982, IoU.mouse: 0.0001, IoU.person: 0.3321, IoU.plate: 0.0009, IoU.platform: 0.0755, IoU.pottedplant: 0.3230, IoU.road: 0.2895, IoU.rock: 0.1916, IoU.sheep: 0.0921, IoU.shelves: 0.0947, IoU.sidewalk: 0.0989, IoU.sign: 0.2324, IoU.sky: 0.6228, IoU.snow: 0.2739, IoU.sofa: 0.2951, IoU.table: 0.2572, IoU.track: 0.0000, IoU.train: 0.4904, IoU.tree: 0.3475, IoU.truck: 0.0657, IoU.tvmonitor: 0.2761, IoU.wall: 0.1437, IoU.water: 0.2975, IoU.window: 0.1419, IoU.wood: 0.1112, Acc.aeroplane: 0.8821, Acc.bag: 0.0247, Acc.bed: 0.1724, Acc.bedclothes: 0.3197, Acc.bench: 0.2174, Acc.bicycle: 0.8792, Acc.bird: 0.8045, Acc.boat: 0.6723, Acc.book: 0.0000, Acc.bottle: 0.7377, Acc.building: 0.1712, Acc.bus: 0.8505, Acc.cabinet: 0.2375, Acc.car: 0.8253, Acc.cat: 0.7592, Acc.ceiling: 0.5647, Acc.chair: 0.2906, Acc.cloth: 0.0566, Acc.computer: 0.8440, Acc.cow: 0.5089, Acc.cup: 0.3013, Acc.curtain: 0.4864, Acc.dog: 0.6872, Acc.door: 0.5730, Acc.fence: 0.5998, Acc.floor: 0.4752, Acc.flower: 0.3873, Acc.food: 0.6532, Acc.grass: 0.4980, Acc.ground: 0.0693, Acc.horse: 0.9036, Acc.keyboard: 0.6012, Acc.light: 0.0870, Acc.motorbike: 0.7819, Acc.mountain: 0.4451, Acc.mouse: 0.0277, Acc.person: 0.3887, Acc.plate: 0.0010, Acc.platform: 0.2723, Acc.pottedplant: 0.7615, Acc.road: 0.3580, Acc.rock: 0.4573, Acc.sheep: 0.7823, Acc.shelves: 0.3599, Acc.sidewalk: 0.5469, Acc.sign: 0.4619, Acc.sky: 0.6542, Acc.snow: 0.6840, Acc.sofa: 0.6829, Acc.table: 0.4045, Acc.track: 0.0000, Acc.train: 0.8347, Acc.tree: 0.3625, Acc.truck: 0.1910, Acc.tvmonitor: 0.3194, Acc.wall: 0.1568, Acc.water: 0.3296, Acc.window: 0.3163, Acc.wood: 0.2683, Prec.aeroplane: 0.4265, Prec.bag: 0.1998, Prec.bed: 0.0514, Prec.bedclothes: 0.1544, Prec.bench: 0.0460, Prec.bicycle: 0.5069, Prec.bird: 0.5233, Prec.boat: 0.2569, Prec.book: nan, Prec.bottle: 0.6440, Prec.building: 0.8230, Prec.bus: 0.7842, Prec.cabinet: 0.3948, Prec.car: 0.7096, Prec.cat: 0.8388, Prec.ceiling: 0.4068, Prec.chair: 0.5684, Prec.cloth: 0.0435, Prec.computer: 0.0211, Prec.cow: 0.5123, Prec.cup: 0.4328, Prec.curtain: 0.2047, Prec.dog: 0.7754, Prec.door: 0.0808, Prec.fence: 0.1493, Prec.floor: 0.5630, Prec.flower: 0.3520, Prec.food: 0.1689, Prec.grass: 0.8365, Prec.ground: 0.5807, Prec.horse: 0.2666, Prec.keyboard: 0.9260, Prec.light: 0.1392, Prec.motorbike: 0.6157, Prec.mountain: 0.2633, Prec.mouse: 0.0001, Prec.person: 0.6950, Prec.plate: 0.0088, Prec.platform: 0.0946, Prec.pottedplant: 0.3593, Prec.road: 0.6019, Prec.rock: 0.2480, Prec.sheep: 0.0946, Prec.shelves: 0.1139, Prec.sidewalk: 0.1077, Prec.sign: 0.3188, Prec.sky: 0.9284, Prec.snow: 0.3135, Prec.sofa: 0.3420, Prec.table: 0.4139, Prec.track: 0.0000, Prec.train: 0.5431, Prec.tree: 0.8941, Prec.truck: 0.0910, Prec.tvmonitor: 0.6703, Prec.wall: 0.6331, Prec.water: 0.7536, Prec.window: 0.2047, Prec.wood: 0.1596
